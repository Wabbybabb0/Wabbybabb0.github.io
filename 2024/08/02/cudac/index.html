<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="CUDA编程：基础与实践学习笔记, Wabbybabbo的摸鱼圣地">
    <meta name="description" content="上班？下班！">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>CUDA编程：基础与实践学习笔记 | Wabbybabbo的摸鱼圣地</title>
    <link rel="icon" type="image/png" href="/grape200x200.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 6.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Wabbybabbo的摸鱼圣地" type="application/atom+xml">
</head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/grape200x200.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Wabbybabbo的摸鱼圣地</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-sharp fa-solid fa-fish" style="zoom: 0.6;"></i>
      
      <span>主页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-soild fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>档案</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="" class="waves-effect waves-light">

      
      <i class="fas fa-list" style="zoom: 0.6;"></i>
      
      <span>分享</span>
      <i class="fas fa-chevron-down" aria-hidden="true" style="zoom: 0.6;"></i>
    </a>
    <ul class="sub-nav menus_item_child ">
      
      <li>
        <a href="/musics">
          
          <i class="fas fa-music" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>音乐</span>
        </a>
      </li>
      
      <li>
        <a href="/movies">
          
          <i class="fas fa-film" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>电影</span>
        </a>
      </li>
      
      <li>
        <a href="/books">
          
          <i class="fas fa-book" style="margin-top: -20px; zoom: 0.6;"></i>
          
          <span>书籍</span>
        </a>
      </li>
      
    </ul>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/grape200x200.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Wabbybabbo的摸鱼圣地</div>
        <div class="logo-desc">
            
            上班？下班！
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-sharp fa-solid fa-fish"></i>
			
			主页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-soild fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			档案
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="javascript:;">
			
				<i class="fa-fw fas fa-list"></i>
			
			分享
			<span class="m-icon"><i class="fas fa-chevron-right"></i></span>
		</a>
            <ul  style="background:  ;" >
              
                <li>

                  <a href="/musics " style="margin-left:75px">
				  
				   <i class="fa fas fa-music" style="position: absolute;left:50px" ></i>
			      
		          <span>音乐</span>
                  </a>
                </li>
              
                <li>

                  <a href="/movies " style="margin-left:75px">
				  
				   <i class="fa fas fa-film" style="position: absolute;left:50px" ></i>
			      
		          <span>电影</span>
                  </a>
                </li>
              
                <li>

                  <a href="/books " style="margin-left:75px">
				  
				   <i class="fa fas fa-book" style="position: absolute;left:50px" ></i>
			      
		          <span>书籍</span>
                  </a>
                </li>
              
            </ul>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/Wabbybabb0/Wabbybabb0.github.io" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/Wabbybabb0/Wabbybabb0.github.io" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/10.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">CUDA编程：基础与实践学习笔记</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/CUDA/">
                                <span class="chip bg-color">CUDA</span>
                            </a>
                        
                            <a href="/tags/GPU/">
                                <span class="chip bg-color">GPU</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/" class="post-category">
                                高性能计算
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2024-08-02
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2025-03-14
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    13.4k
                </div>
                

                

                
                    <div id="busuanzi_container_page_pv" class="info-break-policy">
                        <i class="far fa-eye fa-fw"></i>阅读次数:&nbsp;&nbsp;
                        <span id="busuanzi_value_page_pv"></span>
                    </div>
				
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="第二章-CUDA中的线程组织"><a href="#第二章-CUDA中的线程组织" class="headerlink" title="第二章 CUDA中的线程组织"></a>第二章 CUDA中的线程组织</h1><p><code>cudaDeviceSynchronize();</code>：同步主机和设备，(因为调用输出函数时，输出流先放在缓冲区，但是缓冲区不会自动刷新，只有遇到某种同步操作时才会刷新)，如果没有这句话是不会执行核函数的内容</p>
<p><code>dim3</code>和<code>unit3</code>的区别</p>
<ul>
<li><code>unit3</code>：是一个结构体，具有<code>x</code>、<code>y</code>、<code>z</code>三个成员。适用<code>blockIdx</code>和<code>threadIdx</code></li>
<li><code>dim3</code>：是一个结构体，和<code>unit3</code>类似，适用<code>blockDim</code>和<code>gridDim</code></li>
<li>二者关系，xxxIdx.a的取值范围是yyyDim.a-1，如：<code>blockIdx.x</code>的取值范围是<code>gridDim.x-1</code></li>
</ul>
<h1 id="第三章-简单CUDA程序的基本框架"><a href="#第三章-简单CUDA程序的基本框架" class="headerlink" title="第三章 简单CUDA程序的基本框架"></a>第三章 简单CUDA程序的基本框架</h1><h3 id="3-2-2-设备内存的释放与分配"><a href="#3-2-2-设备内存的释放与分配" class="headerlink" title="3.2.2 设备内存的释放与分配"></a>3.2.2 设备内存的释放与分配</h3><p><code>cudaMalloc()</code><br></p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token class-name">cudaError_t</span> <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span>address<span class="token punctuation">,</span> <span class="token class-name">size_t</span> size<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><p></p>
<ul>
<li><code>address</code>：待分配设备内存的指针。因为内存(地址)本身就是一个指针，所以address是指针的指针</li>
<li><code>size</code>：待分配内存的字节数</li>
<li><code>cudaError_t</code>：作为返回值，如果调用成功则返回<code>cudaSuccess</code></li>
<li><code>(void **)</code>：将某一种类型的双重指针变为void类型的双重指针</li>
<li>功能是改变指针d_x本身的值，即将一个指针赋值给d_x，因此要取d_x的地址，即<code>&amp;d_x</code>，同时该函数不是返回一个指针</li>
<li>配合<code>cudaFree()</code>函数使用</li>
</ul>
<h3 id="3-2-3-主机与设备之间数据的传递"><a href="#3-2-3-主机与设备之间数据的传递" class="headerlink" title="3.2.3 主机与设备之间数据的传递"></a>3.2.3 主机与设备之间数据的传递</h3><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token class-name">cudaError_t</span> <span class="token function">cudaMemcpy</span>
<span class="token punctuation">(</span>
	<span class="token keyword">void</span> <span class="token operator">*</span>dst<span class="token punctuation">,</span>               <span class="token comment">// 目标地址</span>
	<span class="token keyword">const</span> <span class="token keyword">void</span> <span class="token operator">*</span>src<span class="token punctuation">,</span>         <span class="token comment">// 源地址</span>
	<span class="token class-name">size_t</span> count<span class="token punctuation">,</span>            <span class="token comment">// 复制数据的字节数</span>
	<span class="token keyword">enum</span> <span class="token class-name">cudaMemcpyKind</span> kind <span class="token comment">// 标志数据传递方向</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>cudaMemcpy + <code>Host</code>/<code>Device</code> + To + <code>Device</code>/<code>Host</code><br>或者<code>cudaMemcpyDefault</code></p>
<h3 id="3-2-4-核函数中数据与线程的对应"><a href="#3-2-4-核函数中数据与线程的对应" class="headerlink" title="3.2.4 核函数中数据与线程的对应"></a>3.2.4 核函数中数据与线程的对应</h3><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> __global__ <span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">const</span> <span class="token keyword">double</span> <span class="token operator">*</span>x<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">double</span> <span class="token operator">*</span>y<span class="token punctuation">,</span> <span class="token keyword">double</span><span class="token operator">*</span>z<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword">const</span> <span class="token keyword">int</span> n <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    z<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">+</span> y<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>主机中的add函数需要循环，设备中的不需要，只需要数组元素指标与线程指标一一对应即可，在3.3<code>add1.cu</code>中就用了<code>const int n = blockDim.x * blockIdx.x + blockIdx.x</code>来实现对应关系(而主机中的需要用<code>for(int n=0; n&lt;N; n++)</code>)</p>
<h3 id="3-2-6-核函数中if语句的必要性"><a href="#3-2-6-核函数中if语句的必要性" class="headerlink" title="3.2.6 核函数中if语句的必要性"></a>3.2.6 核函数中if语句的必要性</h3><p><code>N</code>为数组元素，$grid_size=\dfrac{N}{block_size}$，如果有余数需要+1，此时线程数为<code>N+block_size</code>，因为<code>grid_size</code>每加一，就多一个<code>block</code>，每一个<code>block</code>有<code>block_size</code>个线程，所以此时线程数为<code>N+block_size</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>原本</th>
<th>后来</th>
</tr>
</thead>
<tbody>
<tr>
<td>N</td>
<td>$10^8$</td>
<td>$10^8+1$</td>
</tr>
<tr>
<td>block_size</td>
<td>128</td>
<td>128</td>
</tr>
<tr>
<td>grid_size</td>
<td>$\dfrac{10^8}{128}=781250$</td>
<td>$\dfrac{10^8}{128}+1=781251$</td>
</tr>
<tr>
<td>实际的线程数$n=block_size*grid_size$</td>
<td>$10^8$</td>
<td>$10^8+128$</td>
</tr>
</tbody>
</table>
</div>
<p>因此需要加上<code>if(n&gt;=N) return;</code>，如果不加上这句，会出现非法的设备内存操作</p>
<h1 id="第四章-CUDA程序的错误检验"><a href="#第四章-CUDA程序的错误检验" class="headerlink" title="第四章 CUDA程序的错误检验"></a>第四章 CUDA程序的错误检验</h1><ul>
<li>在定义宏时，如果一行写不下，则需要在末尾写”\\\”，表示续行</li>
<li>用自定义的宏函数<code>CHECK</code>检查运行时API<img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240829162039.png" alt=""></li>
<li>用以下两句检查核函数<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token function">cudaGetLastError</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>      <span class="token comment">// 捕捉第二个语句之前的最后一个错误</span>
<span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token function">cudaDeviceSynchronize</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 捕捉是否有无法同步主机与设备的错误。因为核函数的调用是异步的，即主机发出调用核函数的命令后会执行后面的语句，不会等待核函数</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
只要在核函数的调用之后 还有其他任何能<strong>返回错误值的API函数</strong>进行同步调用，都能触发主机与设备的同步并捕捉到核函数调用中可能发生的错误。</li>
</ul>
<p>一般情况下，如果需要获得准确的出错位置，需要显式同步。例如调用<code>cudaDeviceSynchronize()</code>函数，或者设置<br></p><pre class="line-numbers language-c" data-language="c"><code class="language-c">$ export CUDA_LAUNCH_BLOCKING<span class="token operator">=</span><span class="token number">1</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre><br>设置完毕后，所有核函数的调用都是同步的，但是最好只用于调试程序，因为这样会影响程序的性能。<p></p>
<p>❓这个<code>cuda-memcheck</code>没给我check出来错误<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240829164737.png" alt=""></p>
<h1 id="第五章-获得GPU加速的关键"><a href="#第五章-获得GPU加速的关键" class="headerlink" title="第五章 获得GPU加速的关键"></a>第五章 获得GPU加速的关键</h1><h3 id="5-1-1-为C-程序计时"><a href="#5-1-1-为C-程序计时" class="headerlink" title="5.1.1 为C++程序计时"></a>5.1.1 为C++程序计时</h3><p>选择浮点数精度</p>
<ul>
<li>单精度浮点数的运行时间👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240829200351.png" alt="单精度浮点数"></li>
<li>双精度浮点数的运行时间👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240829200445.png" alt="双精度浮点数"></li>
</ul>
<h3 id="5-1-2-为CUDA程序计时"><a href="#5-1-2-为CUDA程序计时" class="headerlink" title="5.1.2 为CUDA程序计时"></a>5.1.2 为CUDA程序计时</h3><ol>
<li>仅核函数</li>
</ol>
<ul>
<li>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240829201703.png" alt=""></li>
<li>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240829201718.png" alt=""></li>
</ul>
<ol>
<li>核函数与数据复制</li>
</ol>
<ul>
<li>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240829203507.png" alt=""></li>
<li>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240829203524.png" alt=""><br>对比是否加入了数据复制的用时，可以发现：</li>
<li>核函数的运行时间比数据复制时间要短的多，约占2.5%</li>
<li>如果一个程序的任务仅仅将来自主机端的两个数组相加，再将结果传到主机端，使用GPU的话效率更加低下，(CUDA程序相较于C++程序性能降低</li>
</ul>
<p>关于<code>nvprof</code><br>是一个可用于对CUDA程序进行更多性能剖析的CUDA工具箱里的可执行文件，如果设备计算能力大于8.0不可用，输入<code>nsys nvprof</code>可用<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240829205829.png" alt=""></p>
<ul>
<li>第一列是每类操作(第七列Name)占用时间百分比</li>
<li>第二列时每类操作所用的时间</li>
<li>第三列是每类操作被调用的次数</li>
<li>第四列是每类操作单词调用所用时间的平均值</li>
<li>第五列和第六列分别是每类操作单次调用所用时间的最小值和最大值</li>
</ul>
<h3 id="5-2-1-数据传输的比例"><a href="#5-2-1-数据传输的比例" class="headerlink" title="5.2.1 数据传输的比例"></a>5.2.1 数据传输的比例</h3><p>避免过多的数据经由(连接GPU和CPU)PCIe传递，必须尽量缩减数据传输所花时间的比例(数据在GPU和CPU上传输的时间比计算本身要多的话就得不偿失了)。理论上GPU的显存带宽为几百兆字节，常用的PCIe仅有16GB/s的带宽。</p>
<p><code>nvcc -O3</code>中的<code>-O3</code>是告诉编译器尽可能多地进行优化</p>
<h3 id="5-2-2-算数强度"><a href="#5-2-2-算数强度" class="headerlink" title="5.2.2 算数强度"></a>5.2.2 算数强度</h3><p>进行较复杂的浮点运算，可能会得到更高的加速比，于是将之前的数组相加函数进行更改为👇<br></p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">arithmetic</span><span class="token punctuation">(</span>real <span class="token operator">*</span>x<span class="token punctuation">,</span> <span class="token keyword">const</span> real x0<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> n<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">;</span> n<span class="token operator">&lt;</span>N<span class="token punctuation">;</span> <span class="token operator">++</span>n<span class="token punctuation">)</span>
    <span class="token punctuation">{</span>
        real x_tmp <span class="token operator">=</span> x<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span>
        <span class="token keyword">while</span><span class="token punctuation">(</span><span class="token function">sqrt</span><span class="token punctuation">(</span>x_tmp<span class="token punctuation">)</span> <span class="token operator">&lt;</span> x0<span class="token punctuation">)</span>
        <span class="token punctuation">{</span>
            <span class="token operator">++</span>x_tmp<span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
        x<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">=</span> x_tmp<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p>
<ol>
<li>CPU</li>
</ol>
<ul>
<li>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240830164803.png" alt=""></li>
<li>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240830164907.png" alt=""></li>
</ul>
<ol>
<li>GPU<br>原本执行程序是<code>.\arithmetic2gpu</code>，因为有<code>const int N = atoi(argv[1]);</code>，所以变成<code>.\arithmetic2gpu N</code>，N可以是任何数字，在命令行中手动输入，将会被读取到程序中的N</li>
</ol>
<ul>
<li>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240830210914.png" alt=""></li>
<li><p>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240830211004.png" alt=""></p>
<h3 id="5-2-3-并行规模"><a href="#5-2-3-并行规模" class="headerlink" title="5.2.3 并行规模"></a>5.2.3 并行规模</h3><p>并行规模可用GPU中总的线程数目来衡量<br>小结：</p>
</li>
<li><p>数据传输比例小——减少主机与设备之间的数据传输</p>
</li>
<li>核函数的算术强度较高——提高核函数的算术强度</li>
<li>核函数中定义的线程数目较多——增大核函数的并行规模</li>
</ul>
<h1 id="第六章-CPU的组织内存"><a href="#第六章-CPU的组织内存" class="headerlink" title="第六章 CPU的组织内存"></a>第六章 CPU的组织内存</h1><h3 id="6-2-1-全局内存"><a href="#6-2-1-全局内存" class="headerlink" title="6.2.1 全局内存"></a>6.2.1 全局内存</h3><ol>
<li><p>在核函数中，可直接对静态全局内存变量进行访问，并不需要将它们以参数的形式传给核函数，即：<br>直接访问静态全局内村变量(d_x和d_y[])👇</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c">__device__ <span class="token keyword">int</span> d_x <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">;</span>
__device__ <span class="token keyword">int</span> d_y<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span>

__global__ <span class="token keyword">void</span> <span class="token function">my_kernel</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    d_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> d_x<span class="token punctuation">;</span> <span class="token comment">// 直接访问</span>
    d_y<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+=</span> d_x<span class="token punctuation">;</span> <span class="token comment">// 直接访问</span>
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"d_x = %d\t d_y[0] = %d\t d_y[1] = %d\n"</span><span class="token punctuation">,</span> d_x<span class="token punctuation">,</span> d_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> d_y<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token keyword">int</span> argc<span class="token punctuation">,</span> <span class="token keyword">char</span> <span class="token operator">*</span>argv<span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
    my_kernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 无需传参</span>
    <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>(d_data和value)作为参数传给核函数</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c">__global__ <span class="token keyword">void</span> <span class="token function">myKernel</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>data<span class="token punctuation">,</span> <span class="token keyword">int</span> value<span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">int</span> idx <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    data<span class="token punctuation">[</span>idx<span class="token punctuation">]</span> <span class="token operator">=</span> value<span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token keyword">int</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">int</span> <span class="token operator">*</span>d_data<span class="token punctuation">;</span>
    <span class="token keyword">int</span> value <span class="token operator">=</span> <span class="token number">10</span><span class="token punctuation">;</span>
    <span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_data<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span> <span class="token operator">*</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
    myKernel<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">1</span><span class="token punctuation">,</span> N<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_data<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 需要传参(d_data和value)</span>
    <span class="token function">cudaFree</span><span class="token punctuation">(</span>d_data<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token keyword">return</span> <span class="token number">0</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
<li><p>不可在主机函数中直接访问静态全局内存变量，但可以用<code>cudaMemcpyToSymbol()</code>和<code>cudaMemcpyFromSymbol()</code>函数在静态全局内存与主机内存之间传输数据，这两个CUDA运行时API函数如下(symbol指的是静态全局内存变量)</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token class-name">cudaError_t</span> <span class="token function">cudaMemcpyToSymbol</span>
<span class="token punctuation">(</span>
	<span class="token keyword">const</span> <span class="token keyword">void</span><span class="token operator">*</span> symbol<span class="token punctuation">,</span> <span class="token comment">// 静态全局内存变量名</span>
	<span class="token keyword">const</span> <span class="token keyword">void</span><span class="token operator">*</span> src<span class="token punctuation">,</span>    <span class="token comment">// 主机内存缓冲区指针</span>
	<span class="token class-name">size_t</span> count<span class="token punctuation">,</span>       <span class="token comment">// 复制的字节数</span>
	<span class="token class-name">size_t</span> offset <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token comment">// 从symbol对应设备地址开始偏移的字节数</span>
	cudaMemcpyKind kind <span class="token operator">=</span> cudaMemcpyHostToDevice <span class="token comment">// 可选参数</span>
<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token class-name">cudaError_t</span> <span class="token function">cudaMemcpyFromSymbol</span>
<span class="token punctuation">(</span>
	<span class="token keyword">void</span> <span class="token operator">*</span>dst<span class="token punctuation">,</span>          <span class="token comment">// 主机内存缓冲区指针</span>
	<span class="token keyword">const</span> <span class="token keyword">void</span><span class="token operator">*</span> symbol<span class="token punctuation">,</span> <span class="token comment">// 静态全局内存变量</span>
	<span class="token class-name">size_t</span> count<span class="token punctuation">,</span>       <span class="token comment">// 复制的字节数</span>
	<span class="token class-name">size_t</span> offset <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">,</span>  <span class="token comment">// 从symbol对应设备地址开始偏移的字节数</span>
	cudaMemcpyKind kind <span class="token operator">=</span> cudaMemcpyDeviceToHost <span class="token comment">// 可选参数</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>特点</li>
</ol>
<ul>
<li>所有线程都能访问，全局内存对整个网格的所有线程可见</li>
<li>没有放在GPU芯片上，具有较高延迟和较低的访问速度；是所有设备中内存最大的，容量基本上就是显存容量</li>
<li>可读可写</li>
<li>生命周期：从主机端用<code>cudaMalloc()</code>对他们分配开始，到主机端用<code>cudaFree()</code>释放他们的内存结束</li>
</ul>
<h3 id="6-2-2-常量内存"><a href="#6-2-2-常量内存" class="headerlink" title="6.2.2 常量内存"></a>6.2.2 常量内存</h3><ul>
<li>是有常量缓存的全局内存，仅有64KB</li>
<li>可读不可写</li>
<li>(因为有缓存)访问速度比全局内存高，速度高的前提是一个线程束中的线程(一个线程块中相邻的32个线程)要读取相同的常量内存数据</li>
<li>使用例子：用<code>__constant__</code>定义变量、<code>const int N</code>(这是在主机端定义的变量，通过传值的方式传送给核函数中的线程使用)，核函数对常量内存的访问比对全局内存的访问要快</li>
<li>给核函数传递的参数存放在常量内存中，最多只能用4KB常量内存</li>
</ul>
<h3 id="6-2-4-寄存器"><a href="#6-2-4-寄存器" class="headerlink" title="6.2.4 寄存器"></a>6.2.4 寄存器</h3><p>核函数中定义的且存放在寄存器的有：</p>
<ul>
<li>不加任何限定符的变量</li>
<li>不加任何限定符的数组(也有可能在局部内存中)</li>
<li>内建变量(如<code>gridDim</code>、<code>blockDim</code>、<code>blockIdx</code>、<code>threadIdx</code>、<code>warpSize</code>等等)<br>寄存器可读可写：</li>
<li>写入：<code>const int n = blockDim.x * blockIdx.x + threadIdx.x</code>中的<code>n</code>就是一个寄存器变量</li>
<li>读出：<code>z[n] = x[n] + y[n]</code><br>寄存器变量仅被一个线程可见(以可读可写处代码为例)：</li>
<li>每个线程都有一个变量<code>n</code>的副本，虽然都是同一个变量名<code>n</code>，但是不同线程中该寄存器变量的值可以不同。而且每个线程只能对它的副本进行读写</li>
<li>这就是为什么在主机函数中需要用到<code>for</code>循环写入和读出<code>n</code>(<code>for int n=0; n&lt;N; N++</code>和<code>z[n]=x[n]+y[n]</code>)，而核函数只需要<code>const int n = blockDim.x * blockIdx. + threadIdx.x</code>即可定位到不同的<code>n</code>，因为都是副本</li>
</ul>
<h3 id="6-2-5-局部内存"><a href="#6-2-5-局部内存" class="headerlink" title="6.2.5 局部内存"></a>6.2.5 局部内存</h3><p>寄存器中放不下的变量、索引值不能在编译时就确定的数组都有可能放在局部内存中</p>
<h3 id="6-2-6-共享内存"><a href="#6-2-6-共享内存" class="headerlink" title="6.2.6 共享内存"></a>6.2.6 共享内存</h3><ul>
<li>和寄存器类似，速度仅次于寄存器的读写速度</li>
<li>共享内存对整个<strong>线程块</strong>可见，每个线程块拥有一个共享内存变量的副本，共享内存变量的值在不同的线程块中可以不同。一个线程块中的所有线程都可以访问该线程块的共享变量副本，但是不能访问其他线程块的共享内存变量副本</li>
<li>主要作用是减少对全局内存的访问</li>
</ul>
<h2 id="6-4-用CUDA运行时API函数查询设备"><a href="#6-4-用CUDA运行时API函数查询设备" class="headerlink" title="6.4 用CUDA运行时API函数查询设备"></a>6.4 用CUDA运行时API函数查询设备</h2><p><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240831195051.png" alt=""></p>
<h1 id="第七章-全局内存的合理使用"><a href="#第七章-全局内存的合理使用" class="headerlink" title="第七章 全局内存的合理使用"></a>第七章 全局内存的合理使用</h1><h2 id="7-1-全局内存的合并与非合并访问"><a href="#7-1-全局内存的合并与非合并访问" class="headerlink" title="7.1 全局内存的合并与非合并访问"></a>7.1 全局内存的合并与非合并访问</h2><p>$合并度=\dfrac{线程束请求的字节数}{由该请求导致的所有数据传输处理的字节数}$<br><strong>数据传输对数据地址的要求：在一次数据传输中，从全局内存转移到L2缓存的一片内存首地址一定是一个最小颗粒度(本例是32)的整数倍。</strong></p>
<ol>
<li>顺序的合并访问<pre class="line-numbers language-c" data-language="c"><code class="language-c">__global__ <span class="token keyword">void</span> <span class="token function">add</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>x<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>y<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>z<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	<span class="token keyword">int</span> n <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blcokDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    z<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">+</span> y<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ol>
<ul>
<li>第一个线程块(blockIdx.x=0)中的线程束将访问数组<code>x</code>中第0~31个元素(每个元素类型为float，占四个字节)，则对应32×4=128字节的连续内存</li>
<li>首地址一定是256字节的整数倍(使用CUDA运行时API如<code>cudaMalloc</code>分配的内存的首地址至少是256字节的整数倍)</li>
<li>这样只需要访问4次数据传输即可完成(要求：一次数据传输只能从全局内存读取地址为0~31字节、32~63字节等片段的数据。如果线程束请求的全局内存数据的地址刚好为0~127字节或者128~256字节，就能与<strong>4次数据传输</strong>(0~31、32~63、64~95、96~127四次)所处理的数据完全吻合)</li>
<li>合并度为100%</li>
</ul>
<ol>
<li>乱序的合并访问<pre class="line-numbers language-c" data-language="c"><code class="language-c">__global__ <span class="token keyword">void</span> <span class="token function">add_permuted</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>x<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>y<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>z<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	<span class="token keyword">int</span> tid_permuted <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">^</span> <span class="token number">0x1</span><span class="token punctuation">;</span>
	<span class="token keyword">int</span> n <span class="token operator">=</span> tid_permuted <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blcokDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    z<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">+</span> y<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ol>
<ul>
<li><code>threadIdx.x ^ 0x1</code>异或，将<code>threadIdx.x</code>最后一位翻转</li>
<li>仅把线程块中奇偶次序调转。如第一个线程块中，原本n的顺序为0、1、2、3…。变为1、0、3、2…，即只不过线程号与数组元素指标不完全一致</li>
<li>合并度为100%</li>
</ul>
<ol>
<li>不对齐的非合并访问<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> __global__ <span class="token function">add_offset</span><span class="token punctuation">(</span><span class="token keyword">float</span> <span class="token operator">*</span>x<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>y<span class="token punctuation">,</span> <span class="token keyword">float</span> <span class="token operator">*</span>z<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword">int</span> n <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blcokDim<span class="token punctuation">.</span>x <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span>
    z<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">+</span> y<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
add_permuted<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ol>
<ul>
<li>以第一个线程块为例，第一个线程块中的线程束将访问数组x中第1~32个元素。</li>
<li>假如数组x的首地址为256，那么<code>x[0]</code>为256~259，<code>x[1]</code>为260~263，<code>x[32]</code>为382~387</li>
<li>这将触发5次数据传输，对应的内存地址为256~287字节、288~319字节、320~351字节、352~383字节和384~415字节</li>
<li>合并度为$\dfrac{4}{5}×100=80\%$</li>
</ul>
<ol>
<li>跨越式的非合并访问<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> __global__ <span class="token function">add_stride</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> x<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> y<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> z<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword">int</span> n <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> gridDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    z<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">+</span> y<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
add_stride<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ol>
<ul>
<li>第一个线程块中的线程束将访问数组x中指标为<code>0 + threadIdx.x * gridDim.x=1*128、2*128、3*128...</code>的元素</li>
<li>每一对数据都不在一个连续的32字节的内存片段，因此该线程束的访问将触发32次数据传输</li>
<li>合并度为$\dfrac{4}{32}×100\%=12.5\%$</li>
</ul>
<ol>
<li>广播式的非合并访问<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> __global__ <span class="token function">add_broadcast</span><span class="token punctuation">(</span><span class="token keyword">float</span><span class="token operator">*</span> x<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> y<span class="token punctuation">,</span> <span class="token keyword">float</span><span class="token operator">*</span> z<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword">int</span> n <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> gridDim<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    z<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> y<span class="token punctuation">[</span>n<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
add_stride<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ol>
<ul>
<li>第一个线程块中的线程束将一致地访问数组x中的第0个元素。这实际上只需要一次数据传输(处理32字节的数据)，但整个线程束都在访问同一个内存地址<code>x[0]</code>，只使用了4字节的数据</li>
<li>合并度为$\dfrac{4}{32}×100\%=12.5\%$<h2 id="7-2-例子：矩阵转置"><a href="#7-2-例子：矩阵转置" class="headerlink" title="7.2 例子：矩阵转置"></a>7.2 例子：矩阵转置</h2><code>transpose1()</code>：对矩阵A中数据的访问(读取)是顺序的(/合并的)，对矩阵B中数据的访问(写入)不是顺序的(/非合并的)<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">if</span><span class="token punctuation">(</span>nx <span class="token operator">&lt;</span> N <span class="token operator">&amp;&amp;</span> ny <span class="token operator">&lt;</span> N<span class="token punctuation">)</span>
    <span class="token punctuation">{</span>
        B<span class="token punctuation">[</span>nx <span class="token operator">*</span> N <span class="token operator">+</span> ny<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>ny <span class="token operator">*</span> N <span class="token operator">+</span> nx<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240902095334.png" alt="|277"><br><code>transpose2()</code>：对矩阵A中数据的访问(读取)不是顺序的(/非合并的)，对矩阵B中数据的访问(写入)是顺序的(/合并的)</li>
</ul>
<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">if</span><span class="token punctuation">(</span>nx <span class="token operator">&lt;</span> N <span class="token operator">&amp;&amp;</span> ny <span class="token operator">&lt;</span> N<span class="token punctuation">)</span>
    <span class="token punctuation">{</span>
        B<span class="token punctuation">[</span>ny <span class="token operator">*</span> N <span class="token operator">+</span> nx<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>nx <span class="token operator">*</span> N <span class="token operator">+</span> ny<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240902095353.png" alt="|277"><br>可以发现<code>transpose2()</code>的用时比<code>transpose1()</code>的更久？<br>书上原话：</p>
<ul>
<li>在不能满足读取和写入都是合并的情况下，一般来说应当尽量做到合并地写入</li>
<li>书上的结果是2比1用时更短，因为编译器能够判断一个全局内存变量<strong>在整个核函数的范围都只可读</strong>，则会自动用函数<code>__ldg()</code>读取全局内存，从而对数据的读取进行<strong>缓存</strong>，缓解非合并访问带来的影响。而对于全局内存的写入则没有类似的函数可用<br>👇用了别人的代码后<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240902100134.png" alt=""></li>
</ul>
<h1 id="第八章-共享内存的合理使用"><a href="#第八章-共享内存的合理使用" class="headerlink" title="第八章 共享内存的合理使用"></a>第八章 共享内存的合理使用</h1><h2 id="8-1-例子：数组归约计算"><a href="#8-1-例子：数组归约计算" class="headerlink" title="8.1 例子：数组归约计算"></a>8.1 例子：数组归约计算</h2><ul>
<li>C++实现计算长度较大的累加计算时，会出现”大数吃小数“的现象</li>
<li>CUDA实现比C++实现上述内容时要稳健得多<br>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240911215856.png" alt="|325"><br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240911220431.png" alt="325"><br>上面两个出现大数吃小数的情况</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>精度</th>
<th>reduce_global</th>
<th>reduce_shared</th>
<th>reduce_dynamic</th>
<th>结果</th>
</tr>
</thead>
<tbody>
<tr>
<td>float</td>
<td>6~7ms</td>
<td>7~8ms</td>
<td>7~9ms</td>
<td>123633392.000000.</td>
</tr>
<tr>
<td>double</td>
<td>9~11ms</td>
<td>15~17ms</td>
<td>15~18ms</td>
<td>122999999.998770.</td>
</tr>
</tbody>
</table>
</div>
<p>单精度的结果没有那么离谱，但是离正确答案还有一段距离</p>
<h3 id="8-1-1-仅使用全局内存"><a href="#8-1-1-仅使用全局内存" class="headerlink" title="8.1.1 仅使用全局内存"></a>8.1.1 仅使用全局内存</h3><ul>
<li>访问频繁</li>
<li>使用折半归约法</li>
<li>假设核函数的网格大小和线程块大小的乘积为<code>N</code></li>
<li>对于多线程的程序，两个不同线程中指令的执行次序可能和代码中展现的次序不同</li>
<li>例(循环的前两次)：<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">// 循环的第一次</span>
<span class="token keyword">if</span><span class="token punctuation">(</span>n <span class="token operator">&lt;</span> N<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">{</span>d_x<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">+=</span> d_x<span class="token punctuation">[</span>n <span class="token operator">+</span> N<span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token comment">// 在这次操作中可能会有向数组d_x[N/4]写入数据的操作；</span>
<span class="token comment">// 循环的第二次</span>
<span class="token keyword">if</span><span class="token punctuation">(</span>n <span class="token operator">&lt;</span> N<span class="token operator">/</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">{</span>d_x<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">+=</span> d_x<span class="token punctuation">[</span>n <span class="token operator">+</span> N<span class="token operator">/</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">;</span><span class="token punctuation">}</span> <span class="token comment">// 有可能在线程n=0开始执行这句时，n=N/4还没执行完上一行</span>
<span class="token punctuation">[</span><span class="token number">1</span> <span class="token number">2</span> <span class="token number">3</span> <span class="token number">4</span>
 <span class="token number">5</span> <span class="token number">6</span> <span class="token number">7</span> <span class="token number">8</span><span class="token punctuation">]</span>
N <span class="token operator">=</span> <span class="token number">8</span><span class="token punctuation">,</span> N<span class="token operator">/</span><span class="token number">2</span> <span class="token operator">=</span> <span class="token number">4</span><span class="token punctuation">,</span> 第一次n<span class="token operator">=</span><span class="token number">0</span><span class="token operator">~</span><span class="token number">3</span><span class="token punctuation">,</span> d_x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> d<span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">]</span> 等价于 d_x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token operator">=</span> <span class="token number">1</span><span class="token operator">+</span><span class="token number">5</span> <span class="token operator">=</span> <span class="token number">6</span>
<span class="token punctuation">[</span><span class="token number">6</span> <span class="token number">8</span> <span class="token number">10</span> <span class="token number">12</span><span class="token punctuation">]</span>
N<span class="token operator">/</span><span class="token number">4</span> <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">,</span> 第二次n<span class="token operator">=</span><span class="token number">0</span><span class="token operator">~</span><span class="token number">1</span><span class="token punctuation">,</span> 可能会出现上面还没加完，就执行这里的情况 <span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li>解决方法：要保证核函数中语句的执行顺序与出现顺序一致，用同步函数<code>__syncthreads()</code><ul>
<li>只针对一个线程块中的线程(即只能够同步单个线程块中的线程)<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> __global__ <span class="token function">reduce_global</span><span class="token punctuation">(</span>real<span class="token operator">*</span> d_x<span class="token punctuation">,</span> real<span class="token operator">*</span> d_y<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	<span class="token keyword">const</span> <span class="token keyword">int</span> tid <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
	real<span class="token operator">*</span> x <span class="token operator">=</span> d_x <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
	<span class="token comment">// 不同的线程块指向全局内存中的不同地址</span>
	<span class="token comment">// 上面也可以写成 real* x = &amp;d_x[blockDim.x * blockIdx.x];</span>
	<span class="token comment">// d_x是动态数组，数组名就是数组首地址</span>
	<span class="token comment">// 取d_x[blockDim.x + blockIdx.x]的地址等价于首地址+偏移量(bDimx.x+bIdx.x)</span>
	<span class="token comment">// 定义的x在不同的线程块中指向全局内存中的不同地址！</span>
	
	<span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> offset <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">;</span> offset <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">;</span> offset <span class="token operator">&gt;&gt;=</span> <span class="token number">1</span><span class="token punctuation">)</span>
	<span class="token punctuation">{</span>
		<span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">&lt;</span> offset<span class="token punctuation">)</span>
		<span class="token punctuation">{</span>
			x<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> x<span class="token punctuation">[</span>tid<span class="token operator">+</span>offset<span class="token punctuation">]</span><span class="token punctuation">;</span>
		<span class="token punctuation">}</span>
		<span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 保证同一个线程块内地线程按照代码出现地顺序执行命令</span>
	<span class="token punctuation">}</span>
	<span class="token comment">// 上述for循环保证各个线程块内对其中的数据独立地进行归约</span>
	<span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>
	<span class="token punctuation">{</span>
		d_y<span class="token punctuation">[</span>blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
	<span class="token punctuation">}</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
</li>
</ul>
<pre class="line-numbers language-c" data-language="c"><code class="language-c">real<span class="token operator">*</span> x <span class="token operator">=</span> d_x <span class="token operator">+</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">*</span> blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<ul>
<li>==x在不同的线程块中指向全局内存中的不同地址==，可以理解为上面每一个小数组(书上的例子的小数组长度为$10^8$)为一个<code>d_x</code>，不同的线程块对<code>d_x</code>中不同的部分进行归约，(同一个线程块中的线程的处理速度不一致？</li>
<li>该核函数仅将一个长度为$10^8$的数组<code>d_x</code>归约到一个长度为$\dfrac{10^8}{128}$的数组<code>d_y</code>(书上的操作是把<code>d_y</code>从设备复制到主机里并在主机继续对<code>d_y</code>进行归约得到最终的结果，实际上这样不是很高效)</li>
<li>利用位操作，将<code>blockDim.x/2</code>和<code>offset/=2</code>分别写成了<code>blockDim.x&gt;&gt;1</code>和<code>offset&gt;&gt;=1</code>，在核函数中，<strong>位操作比对应的整数操作高效</strong>。当所涉及的变量在编译期间就知道其可能的取值，编译器会自动用伪操作取代相应的整数操作</li>
</ul>
<h3 id="8-1-2-使用共享内存"><a href="#8-1-2-使用共享内存" class="headerlink" title="8.1.2 使用共享内存"></a>8.1.2 使用共享内存</h3><p>共享内存的主要作用：①减少核函数中对全局内存的访问次数②提高全局访问的合并度<br>共享内存的特点：对整个线程块可见，每个线程块都有一个共享内存变量的副本<br>定义共享内存变量<code>__shared__</code></p>
<ul>
<li>在一个核函数中定义一个共享内存变量，就相当于在<strong>每个线程块中有一个该变量的副本</strong>，虽然每个副本共用一个变量名，但是每个副本都不一样</li>
<li>核函数中，对共享内存变量的操作都是<strong>同时作用在所有的副本上</strong>的<pre class="line-numbers language-c" data-language="c"><code class="language-c">__global__ <span class="token keyword">void</span> <span class="token function">reduce_shared</span><span class="token punctuation">(</span>real <span class="token operator">*</span>d_x<span class="token punctuation">,</span> real <span class="token operator">*</span>d_y<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	<span class="token keyword">const</span> <span class="token keyword">int</span> tid <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
	<span class="token keyword">const</span> <span class="token keyword">int</span> bid <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
	<span class="token keyword">const</span> <span class="token keyword">int</span> n <span class="token operator">=</span> bid<span class="token operator">*</span>blockDimx<span class="token punctuation">.</span>x <span class="token operator">+</span> tid<span class="token punctuation">;</span>
	__shared__ real s_y<span class="token punctuation">[</span><span class="token number">128</span><span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// 共享内存的数组长度与核函数的执行配置参数blockDim.x一样，如果这里写错了，会引起错误或降低核函数性能</span>
	s_y<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">(</span>n<span class="token operator">&lt;</span>N<span class="token punctuation">)</span> <span class="token operator">?</span> d_x<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">:</span> <span class="token number">0.0</span><span class="token punctuation">;</span> <span class="token comment">// 将全局内存中的数据复制到共享内存中</span>
	<span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

	<span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> offset <span class="token operator">=</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">;</span> <span class="token punctuation">)</span>
	<span class="token punctuation">{</span>
		<span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">&lt;</span> offset<span class="token punctuation">)</span>
		<span class="token punctuation">{</span>
			s_y<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">+=</span> s_y<span class="token punctuation">[</span>tid <span class="token operator">+</span> offset<span class="token punctuation">]</span><span class="token punctuation">;</span>
		<span class="token punctuation">}</span>
		<span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
	<span class="token punctuation">}</span>
	<span class="token keyword">if</span><span class="token punctuation">(</span>tid<span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">)</span>
	<span class="token punctuation">{</span>
		d_y<span class="token punctuation">[</span>tid<span class="token punctuation">]</span> <span class="token operator">=</span> s_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
	<span class="token punctuation">}</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/345a4268a6a5f1d9ad0e183fb311f40.jpg" alt=""></li>
<li>一般来说，在核函数中对共享内存访问的次数越多，则由于使用共享内存带来的加速效果越明显</li>
<li>因为有<code>n&lt;N</code>的判断，该函数能够处理<code>N</code>不是线程块大小的整数倍的情形</li>
</ul>
<h3 id="8-1-3-使用动态共享内存"><a href="#8-1-3-使用动态共享内存" class="headerlink" title="8.1.3 使用动态共享内存"></a>8.1.3 使用动态共享内存</h3><p>使用动态共享内存可以减少8.1.2中“<strong>共享内存的数组长度</strong>与核函数的执行配置参数需与<strong>blockDim.x</strong>一样，如果这里写错了，会引起错误或降低核函数性能”错误发生的概率</p>
<p>将静态内存改为动态内存的修改：</p>
<ul>
<li><code>&lt;&lt;&lt;grid_size, block_size, sizeof(real) * block_size&gt;&gt;&gt;</code>，第三个参数就是核函数中每个线程块需要定义的动态共享内存的字节数</li>
<li>改变核函数中共享内存变量的声明方式<ul>
<li>静态：<code>__shared__ real s_y[128];</code></li>
<li>动态：`extern <strong>shared</strong> real s_y[];</li>
</ul>
</li>
</ul>
<p>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240919200305.png" alt="|375"><br>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240919200331.png" alt="375"></p>
<h2 id="8-2-使用共享内存进行矩阵转置"><a href="#8-2-使用共享内存进行矩阵转置" class="headerlink" title="8.2 使用共享内存进行矩阵转置"></a>8.2 使用共享内存进行矩阵转置</h2><p>利用共享内存可以改善全局内存的访问模式，使得对全局内存的读和写都是合并的<br></p><pre class="line-numbers language-c" data-language="c"><code class="language-c">__gobal__ <span class="token keyword">void</span> <span class="token function">transpose1</span><span class="token punctuation">(</span><span class="token keyword">const</span> real <span class="token operator">*</span>A<span class="token punctuation">,</span> real <span class="token operator">*</span>B<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	__shared__ real S<span class="token punctuation">[</span>TILE_DIM<span class="token punctuation">]</span><span class="token punctuation">[</span>TILE_DIM<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// 用一个线程块处理一片32x32的矩阵</span>
	<span class="token keyword">int</span> bx <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> TILE_DIM<span class="token punctuation">;</span>
	<span class="token keyword">int</span> by <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> TILE_DIM<span class="token punctuation">;</span>

	<span class="token keyword">int</span> nx1 <span class="token operator">=</span> bx <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
	<span class="token keyword">int</span> ny1 <span class="token operator">=</span> by <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
	<span class="token keyword">if</span><span class="token punctuation">(</span>nx1 <span class="token operator">&lt;</span> N <span class="token operator">&amp;&amp;</span> ny1 <span class="token operator">&lt;</span> N<span class="token punctuation">)</span>
	<span class="token punctuation">{</span>
		S<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>ny1 <span class="token operator">*</span> N <span class="token operator">+</span> nx1<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// 因为相邻的threadIdx.x与全局内存中相邻的数据对应，所以这里对全局内存的访问是合并的</span>
	<span class="token punctuation">}</span>
	<span class="token function">__syncthreads</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

	<span class="token keyword">int</span> nx2 <span class="token operator">=</span> bx <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
	<span class="token keyword">int</span> ny2 <span class="token operator">=</span> by <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
	<span class="token keyword">if</span><span class="token punctuation">(</span>nx2 <span class="token operator">&lt;</span> N <span class="token operator">&amp;&amp;</span> ny2 <span class="token operator">&lt;</span> N<span class="token punctuation">)</span>
	<span class="token punctuation">{</span>
		B<span class="token punctuation">[</span>nx2 <span class="token operator">*</span> N <span class="token operator">+</span> ny2<span class="token punctuation">]</span> <span class="token operator">=</span> S<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">;</span>
	<span class="token punctuation">}</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p>
<p>上述代码的节选部分👇<br></p><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> nx2 <span class="token operator">=</span> bx <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
<span class="token keyword">int</span> ny2 <span class="token operator">=</span> by <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
<span class="token comment">// 上面这两行改变了对全局内存的访问方式</span>
<span class="token comment">// 这里的bx和by根据blockIdx.x和blockIdx.y的变化而变化。可以视为某个线程块在全局中的偏移量</span>
<span class="token keyword">if</span><span class="token punctuation">(</span>nx2 <span class="token operator">&lt;</span> N <span class="token operator">&amp;&amp;</span> ny2 <span class="token operator">&lt;</span> N<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	B<span class="token punctuation">[</span>nx2 <span class="token operator">*</span> N <span class="token operator">+</span> ny2<span class="token punctuation">]</span> <span class="token operator">=</span> S<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// 相邻的threadIdx.x与全局内存中的数组B中的相邻的数据对应</span>
	<span class="token comment">//B的相邻是ny2，ny2又和threadIdx.x一致相邻</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>第七章<code>transpose1()</code>相关部分👇<br><pre class="line-numbers language-c" data-language="c"><code class="language-c">__global__ <span class="token keyword">void</span> <span class="token function">transpose1</span><span class="token punctuation">(</span><span class="token keyword">const</span> real<span class="token operator">*</span> A<span class="token punctuation">,</span> real<span class="token operator">*</span> B<span class="token punctuation">,</span> <span class="token keyword">const</span> <span class="token keyword">int</span> N<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword">const</span> <span class="token keyword">int</span> nx <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>x <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>x <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
    <span class="token keyword">const</span> <span class="token keyword">int</span> ny <span class="token operator">=</span> blockIdx<span class="token punctuation">.</span>y <span class="token operator">*</span> blockDim<span class="token punctuation">.</span>y <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>nx <span class="token operator">&lt;</span> N <span class="token operator">&amp;&amp;</span> ny <span class="token operator">&lt;</span> N<span class="token punctuation">)</span>
    <span class="token punctuation">{</span>
        B<span class="token punctuation">[</span>nx <span class="token operator">*</span> N <span class="token operator">+</span> ny<span class="token punctuation">]</span> <span class="token operator">=</span> A<span class="token punctuation">[</span>ny <span class="token operator">*</span> N <span class="token operator">+</span> nx<span class="token punctuation">]</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>跟上面代码一样的写法👇<br><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">int</span> nx2 <span class="token operator">=</span> bx <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">;</span>
<span class="token keyword">int</span> ny2 <span class="token operator">=</span> by <span class="token operator">+</span> threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">;</span>
<span class="token comment">// 这样子定义nx2和ny2的话和上面全局内存的访问方式一样</span>
<span class="token keyword">if</span><span class="token punctuation">(</span>nx2 <span class="token operator">&lt;</span> N <span class="token operator">&amp;&amp;</span> ny2 <span class="token operator">&lt;</span> N<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	B<span class="token punctuation">[</span>nx2 <span class="token operator">*</span> N <span class="token operator">+</span> ny2<span class="token punctuation">]</span> <span class="token operator">=</span> S<span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>y<span class="token punctuation">]</span><span class="token punctuation">[</span>threadIdx<span class="token punctuation">.</span>x<span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p></p>
<h2 id="8-3-避免共享内存的bank冲突"><a href="#8-3-避免共享内存的bank冲突" class="headerlink" title="8.3 避免共享内存的bank冲突"></a>8.3 避免共享内存的bank冲突</h2><p>为了获得高的内存带宽，共享内存在物理上被分为32个(刚好等于一个线程束中的线程数目32)同样宽度的、能被同时访问的内存bank</p>
<ul>
<li>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240913182434.png" alt="|350"></li>
<li>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240913182530.png" alt="|350"><br><code>bank</code>宽度为4字节的架构，$\dfrac{128字节(定义的共享内存数组的大小)}{32bank(大小和一个线程束中的线程数目相同)}=4字节/bank$</li>
<li>只要同一个线程束内的多个线程<strong>不同时</strong>访问同一个<code>bank</code>中不同层的数据，该线程束对共享内存的访问就只需要<strong>一次</strong>内存事务</li>
<li>当同一线程的多个线程数试图访问同一个<code>bank</code>中不同层(n层)的数据(将导致n次内存事务)，会发生bank冲突(n路bank冲突)</li>
<li>上面的<code>transpose with shared memory bank conflit</code>是发生了32路bank冲突<ul>
<li><code>B[nx2 * N + ny2] = S[threadIdx.x][threadIdx.y]</code></li>
<li>同一个线程束的32个线程(连续的32个<code>threadIdx.x</code>值)对应<code>S</code>中跨度为32的数据(<code>[threadIdx.y]</code>)</li>
</ul>
</li>
<li>于是将<code>__shared__ real S[TILE_DIM][TILE_DIM]</code>改为<code>__shared__ real S[TILE_DIM][TILE_DIM + 1]</code><ul>
<li>同一个线程束的32个线程(连续的32个<code>threadIdx.x</code>)对应<code>S</code>中跨度为33的数据</li>
<li>如果第一个线程访问第一个<code>bank</code>的第一层，第二个线程则会访问第二个<code>bank</code>的第二层，而不是第一个<code>bank</code>的第二层，以此类推，没有<code>bank</code>冲突<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3_1.jpg" alt=""><br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3_2.jpg" alt=""><br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3_3.jpg" alt=""><br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3_4.jpg" alt=""><br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E6%A1%A3_5.jpg" alt=""><h1 id="第九章-原子函数的合理使用"><a href="#第九章-原子函数的合理使用" class="headerlink" title="第九章 原子函数的合理使用"></a>第九章 原子函数的合理使用</h1></li>
</ul>
</li>
</ul>
<h2 id="9-1-完全在GPU中进行归约"><a href="#9-1-完全在GPU中进行归约" class="headerlink" title="9.1 完全在GPU中进行归约"></a>9.1 完全在GPU中进行归约</h2><ul>
<li>本书使用在先前的核函数的末尾利用<strong>原子函数</strong>进行归约直接得到最终的结果的方法</li>
<li>不能使用👇的原因：不管每个线程块第0号线程的执行次序如何，只有当一个线程的“读-写”操作不被其他线程干扰时，才能得到正确结果<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	d_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+=</span> s_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
如果存在两个线程块第0号线程同时读取d_y[0]的值，那结果就是错误的</li>
<li>原子函数<code>atomicAdd(address, val)</code>：<ul>
<li>第一个参数是待累加的变量的地址</li>
<li>第二个参数是累加的值</li>
<li>“在调用该版本的核函数之前，必须将<code>d_y[0]</code>的值初始化为0”</li>
<li>👇<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment">// threadIdx.x = 0，保证每个线程块的s_y[0]只累加一次</span>
<span class="token punctuation">{</span>
	<span class="token function">atomicAdd</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> s_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token comment">//&amp;d_y[0]可以写成d_y(数组名是数组首个元素的地址)</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
代码中：<br><code>d_x</code>是长度为<code>M</code>的数组、<code>N</code>为元素个数</li>
</ul>
</li>
<li>初始化<code>h_x</code>，复制给<code>d_x</code></li>
<li><strong><code>timing(d_x)</code>：</strong><ul>
<li>重复<code>NUM_REPEATS</code>次</li>
<li>创建事件、计时、查询</li>
<li><strong><code>reduce(d_x)</code>、</strong><ul>
<li>定义网格大小</li>
<li><code>h_y[1]</code>作用是传一个初始值为0的值给<code>d_y</code>，满足<code>d_y[0]</code>的值初始化为0的要求<ul>
<li><strong><code>reduce(d_x, d_y, N)</code>：动态内存<code>&lt;&lt;&lt;grid_size, block_size, sizeof(real) * block_size&gt;&gt;&gt;</code></strong><ul>
<li>使用动态内存进行折半相加</li>
<li>使用<code>atomicAdd</code>对每个线程块的首个元素相加得到最终结果</li>
</ul>
</li>
</ul>
</li>
<li>将结果从<code>d_y</code>复制回<code>h_y</code>中</li>
<li>释放内存</li>
</ul>
</li>
<li>结束计时，打印计时结果和最后一次的求和结果</li>
</ul>
</li>
<li>释放<code>d_x</code>和<code>h_x</code>的内存</li>
</ul>
<p>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240919200542.png" alt="375"><br>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240919200554.png" alt="375"><br>确实是比先前的提升约2ms</p>
<h2 id="9-3-例子：邻居列表的建立"><a href="#9-3-例子：邻居列表的建立" class="headerlink" title="9.3 例子：邻居列表的建立"></a>9.3 例子：邻居列表的建立</h2><p><code>MN</code>是每个原子的最多邻居原子数<br><code>NN[n]</code>是第n个粒子的邻居个数<br><code>NL[n * MN + k]</code>是第n个粒子的第k个邻居的指标</p>
<h3 id="9-3-1-C-版本的开发"><a href="#9-3-1-C-版本的开发" class="headerlink" title="9.3.1 C++版本的开发"></a>9.3.1 C++版本的开发</h3><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token keyword">void</span> <span class="token function">find_neighbor</span><span class="token punctuation">(</span><span class="token keyword">int</span> <span class="token operator">*</span>NN<span class="token punctuation">,</span> <span class="token keyword">int</span> <span class="token operator">*</span>NL<span class="token punctuation">,</span> <span class="token keyword">const</span> real<span class="token operator">*</span> x<span class="token punctuation">,</span> <span class="token keyword">const</span> real<span class="token operator">*</span> y<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> n <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> n <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> n<span class="token operator">++</span><span class="token punctuation">)</span>
    <span class="token punctuation">{</span>
        NN<span class="token punctuation">[</span>n<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

	<span class="token comment">// n1和n2代表两个可能互为邻居的原子</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> n1 <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">;</span> n1 <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> <span class="token operator">++</span>n1<span class="token punctuation">)</span>
    <span class="token punctuation">{</span>
        real x1 <span class="token operator">=</span> x<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token punctuation">;</span>
        real y1 <span class="token operator">=</span> y<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token punctuation">;</span>
        <span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> n2 <span class="token operator">=</span> n1 <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">;</span> n2 <span class="token operator">&lt;</span> N<span class="token punctuation">;</span> <span class="token operator">++</span>n2<span class="token punctuation">)</span> <span class="token comment">// 因为n1和n2互为邻居，所以只考虑n2&gt;n1的情形</span>
        <span class="token punctuation">{</span>
            real x12 <span class="token operator">=</span> x<span class="token punctuation">[</span>n2<span class="token punctuation">]</span> <span class="token operator">-</span> x1<span class="token punctuation">;</span>
            real y12 <span class="token operator">=</span> y<span class="token punctuation">[</span>n2<span class="token punctuation">]</span> <span class="token operator">-</span> y1<span class="token punctuation">;</span>
            real distance_square <span class="token operator">=</span> x12 <span class="token operator">*</span> x12 <span class="token operator">+</span> y12 <span class="token operator">*</span> y12<span class="token punctuation">;</span> <span class="token comment">// </span>
            <span class="token keyword">if</span><span class="token punctuation">(</span>distance_square <span class="token operator">&lt;</span> cutoff_square<span class="token punctuation">)</span>
            <span class="token punctuation">{</span>
                NL<span class="token punctuation">[</span>n1 <span class="token operator">*</span> MN <span class="token operator">+</span> NN<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> n2<span class="token punctuation">;</span> <span class="token comment">// 先添加邻居信息，再对邻居个数++</span>
                NL<span class="token punctuation">[</span>n2 <span class="token operator">*</span> MN <span class="token operator">+</span> NN<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> n1<span class="token punctuation">;</span>
            <span class="token punctuation">}</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="9-3-2-利用原子操作的CUDA版本"><a href="#9-3-2-利用原子操作的CUDA版本" class="headerlink" title="9.3.2 利用原子操作的CUDA版本"></a>9.3.2 利用原子操作的CUDA版本</h3><p>如果仍然使用9.3.1中的<code>find_neighbor</code>函数，会导致“<strong>并发写入冲突</strong>”<br>一个线程与一个原子对应</p>
<ul>
<li>与n1对应的线程👇<pre class="line-numbers language-c" data-language="c"><code class="language-c">d_NL<span class="token punctuation">[</span>n1 <span class="token operator">*</span> MN <span class="token operator">+</span> NN<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> n2<span class="token punctuation">;</span> 
d_NL<span class="token punctuation">[</span>n2 <span class="token operator">*</span> MN <span class="token operator">+</span> NN<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> n1<span class="token punctuation">;</span> <span class="token comment">// 第二条语句</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li>与n2对应的线程👇<pre class="line-numbers language-c" data-language="c"><code class="language-c">d_NL<span class="token punctuation">[</span>n2 <span class="token operator">*</span> MN <span class="token operator">+</span> NN<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> n1<span class="token punctuation">;</span> <span class="token comment">// 第一条语句</span>
d_NL<span class="token punctuation">[</span>n1 <span class="token operator">*</span> MN <span class="token operator">+</span> NN<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> n2<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
书上原话“在与<code>n1</code>对应的线程中，第二条语句代表我们试图对<code>d_NN[n2]</code>进行累加操作。但是，在与<code>n2</code>对应的线程中，第一条语句代表我们也试图对<code>d_NN[n2]</code>进行累加操作”<br>需要用原子函数：<pre class="line-numbers language-c" data-language="c"><code class="language-c">d_NL<span class="token punctuation">[</span>n1 <span class="token operator">*</span> MN <span class="token operator">+</span> d_NN<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> n2<span class="token punctuation">;</span>
d_NL<span class="token punctuation">[</span>n2 <span class="token operator">*</span> MN <span class="token operator">+</span> d_NN<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> n1<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
</li>
</ul>
<p>合理利用返回值：<br>可以将👇代码<br></p><pre class="line-numbers language-c" data-language="c"><code class="language-c">NL<span class="token punctuation">[</span>n1 <span class="token operator">*</span> MN <span class="token operator">+</span> NN<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> n2<span class="token punctuation">;</span>
NL<span class="token punctuation">[</span>n2 <span class="token operator">*</span> MN <span class="token operator">+</span> NN<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">]</span> <span class="token operator">=</span> n1<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>改写为👇<br><pre class="line-numbers language-c" data-language="c"><code class="language-c">NL<span class="token punctuation">[</span>n1 <span class="token operator">*</span> MN <span class="token operator">+</span> NN<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> n2<span class="token punctuation">;</span>
NN<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">;</span>
NL<span class="token punctuation">[</span>n2 <span class="token operator">*</span> MN <span class="token operator">+</span> NN<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> n1<span class="token punctuation">;</span>
NN<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token operator">++</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><br>但如果类似地改写原子函数的代码：<br><pre class="line-numbers language-c" data-language="c"><code class="language-c">d_NL<span class="token punctuation">[</span>n1 <span class="token operator">*</span> MN <span class="token operator">+</span> <span class="token function">atomicAdd</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_NN<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> n2<span class="token punctuation">;</span>
d_NL<span class="token punctuation">[</span>n2 <span class="token operator">*</span> MN <span class="token operator">+</span> <span class="token function">atomicAdd</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_NN<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token operator">=</span> n1<span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre><br>👆改写为👇<br><pre class="line-numbers language-c" data-language="c"><code class="language-c">d_NL<span class="token punctuation">[</span>n1 <span class="token operator">*</span> MN <span class="token operator">+</span> d_NN<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> n2<span class="token punctuation">;</span>
<span class="token function">atomicAdd</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_NN<span class="token punctuation">[</span>n1<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
d_NL<span class="token punctuation">[</span>n2 <span class="token operator">*</span> MN <span class="token operator">+</span> d_NN<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> n1<span class="token punctuation">;</span>
<span class="token function">atomicAdd</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_NN<span class="token punctuation">[</span>n2<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre><p></p>
<ul>
<li>原子函数的操作本身是立即生效的，且在原子操作的执行过程中其他线程无法同时修改该变量</li>
<li>不同的线程可能会同时访问<code>d_NN[n1]</code>和<code>d_NN[n2]</code>，如果两个线程几乎同时执行对 <code>d_NN[n1]</code> 的 <code>atomicAdd</code> 操作，那么尽管操作本身是原子的，它们的执行顺序却是不确定的，一个线程可能在另一个线程更新<code>d_NN[n1]</code>之前就读到了该值<br>正确写法👇<pre class="line-numbers language-none"><code class="language-none">int tmp1 = atomicAdd(&amp;d_NN[n1], 1);
d_NL[n1 * MN + tmp1] = n2;
int tmp2 = atomicAdd(&amp;d_NN[n2], 1);
d_NL[n2 * MN + tmp1] = n1;<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
使用临时变量<code>tmp1</code>和<code>tmp2</code>保存<code>d_NN[n1]</code>和<code>d_NN[n2]</code>的旧值</li>
</ul>
<p>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240921115244.png" alt="375"><br>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240921115308.png" alt="375"></p>
<p>在核函数<code>find_neighbor_no_atomic</code>中，<br>①将<code>d_NL[n1 * MN + count++]</code>改为<code>d_NL[(count++) * N + n1]</code><br>②<code>const int n1 = blockIdx.x * blockDim.x + threadIdx.x;</code></p>
<ul>
<li>前者的索引中：每个线程的地址跨度为<code>MN</code></li>
<li>后者的索引中：每个线程在每次循环时访问相邻的内存位置</li>
</ul>
<p>对于<code>find_neighbor_not_atomic</code><br>①将<code>if((distance_square) &lt; cutoff_square &amp;&amp; (n2 != n1))</code><br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240921115244.png" alt="375"><br>改为<code>if((n2 != n1) &amp;&amp; (distance_square) &lt; cutoff_square)</code>，用时变多<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240921170942.png" alt="375"></p>
<p>对比使用寄存器变量与不使用寄存器变量<br>使用👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240921115244.png" alt="375"><br>不使用👇，用时变多<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240921171012.png" alt="375"></p>
<h1 id="第十章-线程束基本函数与协作组"><a href="#第十章-线程束基本函数与协作组" class="headerlink" title="第十章 线程束基本函数与协作组"></a>第十章 线程束基本函数与协作组</h1><h2 id="10-1-单指令-多线程执行模式"><a href="#10-1-单指令-多线程执行模式" class="headerlink" title="10.1 单指令-多线程执行模式"></a>10.1 单指令-多线程执行模式</h2><p>并发和同步：</p>
<ul>
<li>并发：侧重任务的(逻辑)同时进行，在同一段时间内<strong>多个任务交替进行</strong></li>
<li>同步：侧重控制人物的执行顺序，保证它们在合适的时刻访问共享资源</li>
</ul>
<p>单指令-多线程：同一时刻，一个线程束中的线程只能执行一个共同的指令或者闲置<br>分治发散：一个线程束中的线程顺序地执行判断语句中的不同分支(分支是依次执行的)</p>
<p>一个SM可以处理一个或多个线程块，一个线程块不会被分配到不同的SM中<br>一个线程块可以氛围若干线程束</p>
<h2 id="10-3-更多线程束内的基本函数"><a href="#10-3-更多线程束内的基本函数" class="headerlink" title="10.3 更多线程束内的基本函数"></a>10.3 更多线程束内的基本函数</h2><p><code>mask</code>为掩码，是一个32位的无符号整数，用于指定要参与计算的线程，掩码中的一个二进制位为0/1代表对应的线程参与/不参与计算<br>①<code>__ballot_sync(mask, predicate)</code>：返回一个新的掩码</p>
<ul>
<li><code>mask</code>先决定线程束内第n(n=1~32)个线程是否参与计算(0/1)</li>
<li><code>predicate</code>用于判断参与计算的线程是否满足条件，如果满足则该线程对应的<code>predicate</code>为1，对应的<code>mask</code>取1的比特位，否则对应的<code>predicate</code>为0，对应的<code>mask</code>取0</li>
</ul>
<p>②<code>__all_sync(mask, predicate)</code>：返回0/1</p>
<ul>
<li>线程束内所有参与的线程对应的<code>predicate</code>值都不为0才返回1，否则返回0</li>
<li>类似于选举操作，所有参选人都同意时通过<ul>
<li>例：<code>int result = __all_sync(FULL_MASK, tid);</code>如果所有线程的 <code>tid</code> 都为真（非零），函数返回 1，表示条件对所有线程都满足；否则返回 0，表示至少有一个线程的 <code>tid</code> 为零。</li>
</ul>
</li>
</ul>
<p>③<code>__any_sync(mask, predicate)</code>：返回0/1</p>
<ul>
<li>线程束内所有参与的线程对应的<code>predicate</code>值只要有一个不为0就返回1，如果全是0才返回0</li>
<li>类似选举操作，只要有一个参选人同意就通过</li>
</ul>
<p>④<code>__shfl_sync(mask, var, srcLane, width);</code>每个子组中参与的线程获取<code>land_id</code>为<code>srcLane</code>的线程中的变量</p>
<ul>
<li><code>land_id = threadIdx.x % w; = threadIdx.x &amp; (w - 1);</code></li>
<li><code>mask</code>：表示线程束内参与的线程</li>
<li><code>var</code>：表示当前线程的变量</li>
<li><code>srcLane</code>：表示从哪个线程索引读取<code>v</code>的值</li>
<li><code>width</code>：表示参与这个<code>shuffle</code>操作的<code>warp</code>的宽度<ul>
<li>例：<code>__shfl_sync(FULL_MASK, tid, 2, 8)</code><ul>
<li><code>8</code>表示<code>__shfl_sync()</code>操作只在8个线程的小组中进行，对于32线程的<code>wrap</code>，线程被分为4组有8个线程的子组(0-7, 8-15, 16-23, 24-31)</li>
<li><code>2</code>表示源线程索引，每个线程都会读取第2号线程的<code>tid</code>值并存到<code>value</code>变量中</li>
<li><code>tid</code>表示每个线程的局部变量<pre class="line-numbers language-c" data-language="c"><code class="language-c">__global__ <span class="token keyword">void</span> <span class="token function">shuffleExample</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token keyword">int</span> tid <span class="token operator">=</span> threadIdx<span class="token punctuation">.</span>x <span class="token operator">%</span> <span class="token number">32</span><span class="token punctuation">;</span>  <span class="token comment">// 假设每个线程的tid是线程索引（0~31）</span>
    <span class="token keyword">int</span> value <span class="token operator">=</span> <span class="token function">__shfl_sync</span><span class="token punctuation">(</span><span class="token number">0xFFFFFFFF</span><span class="token punctuation">,</span> tid<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token function">printf</span><span class="token punctuation">(</span><span class="token string">"Thread %d got value %d\n"</span><span class="token punctuation">,</span> tid<span class="token punctuation">,</span> value<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token comment">//打印结果👇</span>
Thread <span class="token number">0</span> got value <span class="token number">2</span>
Thread <span class="token number">1</span> got value <span class="token number">2</span>
Thread <span class="token number">2</span> got value <span class="token number">2</span>
Thread <span class="token number">3</span> got value <span class="token number">2</span>
Thread <span class="token number">4</span> got value <span class="token number">2</span>
Thread <span class="token number">5</span> got value <span class="token number">2</span>
Thread <span class="token number">6</span> got value <span class="token number">2</span>
Thread <span class="token number">7</span> got value <span class="token number">2</span>
Thread <span class="token number">8</span> got value <span class="token number">10</span>
Thread <span class="token number">9</span> got value <span class="token number">10</span>
Thread <span class="token number">10</span> got value <span class="token number">10</span>
Thread <span class="token number">11</span> got value <span class="token number">10</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
Thread <span class="token number">30</span> got value <span class="token number">26</span>
Thread <span class="token number">31</span> got value <span class="token number">26</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
</ul>
</li>
</ul>
</li>
<li>将一个线程中的数据广播到所有(包括自己)线程</li>
</ul>
<p>⑤<code>__shfl_up_sync(mask, var, delta, width);</code></p>
<ul>
<li><code>delta</code>：表示每个线程从前面多少个线程处获取数据</li>
<li><code>width</code>：决定了<code>warp</code>内的分组范围，通信只在指定大小的组内进行<ul>
<li>例：<code>__shfl_up_sync(mask, var, 1, 8);</code></li>
</ul>
</li>
<li><code>vat</code>：决定获取的数据来源</li>
</ul>
<div class="table-container">
<table>
<thead>
<tr>
<th>线程ID</th>
<th>tid</th>
<th>执行后的tid</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>1</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
</tbody>
</table>
</div>
<ul>
<li>是一种将数据向上平移的操作</li>
</ul>
<p>⑥<code>__shfl_down_sync(mask, var, delta, width);</code></p>
<ul>
<li>是一种将数据向下平移的操作</li>
</ul>
<p>⑦<code>__shfl_xor_sync(mask, var, landMask, width);</code><br>线程<code>i</code>与线程<code>i ^ landMask</code>(这里表示异或)交换数据<br>例子：<code>landMask=1</code>、<code>width=8</code></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>线程ID</th>
<th>tid</th>
<th>执行后的tid</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>2</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>5</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>4</td>
</tr>
<tr>
<td>6</td>
<td>6</td>
<td>7</td>
</tr>
<tr>
<td>7</td>
<td>7</td>
<td>6</td>
</tr>
<tr>
<td>8</td>
<td>8</td>
<td>9</td>
</tr>
<tr>
<td>9</td>
<td>9</td>
<td>8</td>
</tr>
<tr>
<td>10</td>
<td>10</td>
<td>11</td>
</tr>
<tr>
<td>11</td>
<td>11</td>
<td>10</td>
</tr>
<tr>
<td>12</td>
<td>12</td>
<td>13</td>
</tr>
<tr>
<td>13</td>
<td>13</td>
<td>12</td>
</tr>
<tr>
<td>14</td>
<td>14</td>
<td>15</td>
</tr>
<tr>
<td>15</td>
<td>15</td>
<td>14</td>
</tr>
</tbody>
</table>
</div>
<p>以<code>__shlf</code>开头的函数为洗牌函数，好处是<strong>使得线程束中的线程彼此之间可以直接交换数据，而不是通过共享内存或全局内存来进行的</strong>。洗牌指令比共享内存有更低的延迟，并且该指令在执行数据交换时不消耗额外的内存</p>
<p><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240922162221.png" alt=""></p>
<ul>
<li><code>all_sync(FULL_MASK):0</code>，线程0的<code>tid</code>为0，不是全部参与的线程的<code>predicate</code>值都为1，所以为0</li>
<li><code>all_sync(mask1):1</code>，线程0没有参与，全部参与的线程的<code>predicate</code>值都为1，所以为1</li>
<li><code>any_sync(FULL_MASK):1</code>，线程0的<code>tid</code>为0，只要参与的线程的<code>predicate</code>值至少有一个为1则为1，所以为1</li>
<li><code>any_sync(mask2):1</code>，线程0的<code>tid</code>为0，参与的线程的只有线程0，<code>predicate</code>值只有0，所以为0</li>
</ul>
<h3 id="10-3-2-利用线程束洗牌函数进行规约计算"><a href="#10-3-2-利用线程束洗牌函数进行规约计算" class="headerlink" title="10.3.2 利用线程束洗牌函数进行规约计算"></a>10.3.2 利用线程束洗牌函数进行规约计算</h3><pre class="line-numbers language-c" data-language="c"><code class="language-c">real y <span class="token operator">=</span> s_y<span class="token punctuation">[</span>tid<span class="token punctuation">]</span><span class="token punctuation">;</span> <span class="token comment">// 将共享内存中的数据复制到寄存器，在线程束内使用洗牌函数进行归约时，不需要明显地使用共享内存</span>
<span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> offset <span class="token operator">=</span> <span class="token number">16</span><span class="token punctuation">;</span> offset <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">;</span> offset <span class="token operator">&gt;&gt;=</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	y <span class="token operator">+=</span> <span class="token function">__shfl_down_sync</span><span class="token punctuation">(</span>FULL_MASK<span class="token punctuation">,</span> y<span class="token punctuation">,</span> offset<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// y是读取的值，offset是向后移的个数</span>
<span class="token punctuation">}</span>
<span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	<span class="token function">atomicAdd</span><span class="token punctuation">(</span>d_y<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>👆理解：</p>
<ul>
<li>将共享内存中的数据复制到寄存器，在线程束内使用洗牌函数进行归约时，不需要明显地使用共享内存</li>
<li>洗牌函数先读取各个线程中y的值，再将洗牌操作的结果写入各个线程的y中<ul>
<li>假设<code>y(tid = n) = n</code><ul>
<li>`offset=16<ul>
<li><code>y(tid=0) += __shfl_down_sync(FULL_MASK, y(tid=0), offset);</code><ul>
<li><code>y(tid=0) = 0</code></li>
<li><code>__shfl_down_sync() -&gt; y(tid=0)' = y(tid=16) = 16</code>，<code>'</code>表示后来的</li>
<li><code>y(tid=0) = y(tid=0) + y(tid=0)' = 0 + 16 = 16</code></li>
</ul>
</li>
<li><code>y(tid=1) = 1 + 17 = 18</code></li>
<li>…</li>
<li><code>y(tid=15) = 15 + 31 = 46</code></li>
</ul>
</li>
<li><code>offset=8</code><ul>
<li><code>y(tid=0) = y(tid=0) + y(tid=7)</code></li>
<li>…</li>
</ul>
</li>
<li><code>offset=1</code><ul>
<li><code>y(tid=0) = y(tid=0) + y(tid=1)</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="10-4-协作组"><a href="#10-4-协作组" class="headerlink" title="10.4 协作组"></a>10.4 协作组</h2><p>协作组：看作线程块和线程束同步机制的推广</p>
<ul>
<li>使用协作组的功能时需要在相关源文件包含如下头文件：<br><code>#include&lt;cooperative_groups.h&gt;</code></li>
<li>导入命名空间<code>cooprtative_groups</code>中的内容：<br><code>using namespace cooperative_groups;</code></li>
</ul>
<p>定义并初始化一个<code>thread_block</code>对象：<br><code>thread_block g = this_thread_block();</code>，<code>g</code>就代表了线程块</p>
<ul>
<li>等价关系：</li>
<li><code>g.sync()</code>↔<code>__syncthreads()</code></li>
<li><code>g.group_index()</code>↔<code>blockIdx</code></li>
<li><code>g.thread_index()</code>↔<code>threadIdx</code></li>
</ul>
<p><code>tiled_partition()</code>将一个线程块分为若干片(<code>tile</code>)，每一片构成一个新的线程组，大小只能是2、4、8、16、32</p>
<ul>
<li>模板化：<br><code>thread_block_tile&lt;32&gt; g32 = tiled_partition&lt;32&gt;(this_thread_block());</code><br><code>thread_block_tile&lt;4&gt; g4 = tiled_partition&lt;4&gt;(this_thread_block());</code><br>这样定义的线程组称为<strong>线程块片</strong>，线程块片函数不同的地方：</li>
<li>线程组内的所有线程都必须参与相关函数的运算</li>
<li>宽度就是线程块片的大小</li>
</ul>
<pre class="line-numbers language-c" data-language="c"><code class="language-c">real y <span class="token operator">=</span> s_y<span class="token punctuation">[</span>tid<span class="token punctuation">]</span><span class="token punctuation">;</span>
thread_block_tile<span class="token operator">&lt;</span><span class="token number">32</span><span class="token operator">&gt;</span> g <span class="token operator">=</span> tiled_partition<span class="token operator">&lt;</span><span class="token number">32</span><span class="token operator">&gt;</span><span class="token punctuation">(</span><span class="token function">this_thread_block</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">for</span><span class="token punctuation">(</span><span class="token keyword">int</span> i <span class="token operator">=</span> g<span class="token punctuation">.</span><span class="token function">size</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;&gt;</span> <span class="token number">1</span><span class="token punctuation">;</span> i <span class="token operator">&gt;</span> <span class="token number">0</span><span class="token punctuation">;</span> i <span class="token operator">&gt;&gt;=</span> <span class="token number">1</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    y <span class="token operator">+=</span> g<span class="token punctuation">.</span><span class="token function">shfl_down</span><span class="token punctuation">(</span>y<span class="token punctuation">,</span> i<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>
<span class="token keyword">if</span><span class="token punctuation">(</span>tid <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    <span class="token function">atomicAdd</span><span class="token punctuation">(</span>d_y<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>把线程划分32个线程一组的，其他的与洗牌函数的步骤差不多，只是使用的方法不一样，所以他们两种方法的用时也差不多</p>
<p>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240922220201.png" alt="275"><br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240922220210.png" alt="275"><br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240922220219.png" alt="275"><br>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240922220240.png" alt="275"><br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240922220254.png" alt="275"><br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240922220302.png" alt="275"></p>
<h2 id="10-5-数组规约程序的进一步优化"><a href="#10-5-数组规约程序的进一步优化" class="headerlink" title="10.5 数组规约程序的进一步优化"></a>10.5 数组规约程序的进一步优化</h2><h3 id="10-5-1-提高线程利用率"><a href="#10-5-1-提高线程利用率" class="headerlink" title="10.5.1 提高线程利用率"></a>10.5.1 提高线程利用率</h3><p>“如果能够提高归约之前所做计算的比例，则应该可以从整体上升对线程的利用率…，可以在归约之前将多个全局内存数组的数据累加到一个共享内存数组的一个元素中”</p>
<p>“不要让一个线程处理相邻的若干数据，因为这必然导致全局内存的非合并访问”，如何理解这句话(这句话本人读了好一会才理明白)：</p>
<ul>
<li>什么是合并访问？<ul>
<li>$合并度=\dfrac{线程束请求的字节数}{由该请求导致的所有数据传输处理的字节数}$</li>
<li>合并访问就是合并度100%的情况，注意：线程的组织情况是以线程束为单位</li>
</ul>
</li>
<li>为什么一个线程处理会导致非合并<ul>
<li>(以下是带有主观的解释)一个线程处理相邻的数据，如</li>
<li><code>tid=0 -&gt; 访问 d_x[0], d_x[1], d_x[2], d_x[3]</code></li>
<li><code>tid=1 -&gt; 访问 d_x[4], d_x[5], d_x[6], d_x[7]</code></li>
<li>在一个线程束内，每一时刻每个线程访问的数据不是连续的(<code>d_x[tid * 4]</code>)，数据的传输的首地址某个最小颗粒度的倍数</li>
<li>假设需要请求的数据为<code>d_x[0]~d_x[31]</code>，每个元素大小为4字节，某个最小颗粒度为32</li>
<li>在第一个时刻中，<code>tid = 0 -&gt; 0 ... tid = 7 -&gt; 28</code></li>
<li>在第二个时刻中，<code>tid = 0 -&gt; 1 ... tid = 7 -&gt; 29</code></li>
<li>在第三个时刻中，<code>tid = 0 -&gt; 2 ... tid = 7 -&gt; 30</code></li>
<li>在第四个时刻中，<code>tid = 0 -&gt; 3 ... tid = 7 -&gt; 31</code></li>
<li>$合并度=\dfrac{线程束请求的字节数}{由该请求导致的所有数据传输处理的字节数}=\dfrac{128}{128*4}=\dfrac{1}{4}$，4是代表进行了4次从0~128字节的访问(即<code>d_x[0]~d_x[31]</code>)</li>
</ul>
</li>
<li>怎么样访问才是合并的？<ul>
<li>相邻线程访问连续的地址，例子见第七章第一节的顺序的合并访问</li>
</ul>
</li>
</ul>
<p>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240924211910.png" alt="375"><br>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240924211937.png" alt="375"><br>可以发现优化后在时间和精度上都有所提升！</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c">reduce_cp<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>GRID_SIZE<span class="token punctuation">,</span> BLOCK_SIZE<span class="token punctuation">,</span> smem<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_x<span class="token punctuation">,</span> d_y<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
reduce_cp<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>real<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_y<span class="token punctuation">,</span> d_y<span class="token punctuation">,</span> GRID_SIZE<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 有GRID_SIZE个块需要归约</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<ul>
<li>用<code>d_y[bid] = y;</code>代替了<code>atomicAdd(d_y, y)</code></li>
<li>使用两个核函数可以获得更加精确的结果，这是因为使用两个核函数时，将数组<code>d_y</code>归约到最终结果的计算使用了折半求和，比直接累加(使用原子函数或复制到主机再累加的情况)更稳健</li>
</ul>
<h3 id="10-5-2-避免反复分配与释放设备内存"><a href="#10-5-2-避免反复分配与释放设备内存" class="headerlink" title="10.5.2 避免反复分配与释放设备内存"></a>10.5.2 避免反复分配与释放设备内存</h3><p>在10.5.1的<code>reduce()</code>函数中，需要为数组<code>d_y</code>分配与释放设备内存。实际上，<strong>设备内存的分配与释放是比较耗时的</strong><br></p><pre class="line-numbers language-c" data-language="c"><code class="language-c">real <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token keyword">const</span> real<span class="token operator">*</span> d_x<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
	<span class="token keyword">const</span> <span class="token keyword">int</span> ymem <span class="token operator">=</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>real<span class="token punctuation">)</span> <span class="token operator">*</span> GRID_SIZE<span class="token punctuation">;</span>
	<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
	<span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token operator">&amp;</span>d_y<span class="token punctuation">,</span> ymem<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 分配内存</span>
	<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
	<span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token function">cudaFree</span><span class="token punctuation">(</span>d_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 释放内存	</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><br>解决方法：使用静态全局内存代替动态全局内存，因为静态内存在编译期间就会分配好<p></p>
<ul>
<li>定义静态全局内存变量：<code>__device__ real static_y[GRID_SIZE];</code></li>
<li>在不改变核函数代码的情况下，可以用<code>cudaGetSymbolAddress()</code>获得一个指向该静态全局内存的指针<pre class="line-numbers language-c" data-language="c"><code class="language-c">__device__ real static_y<span class="token punctuation">[</span>GRID_SIZE<span class="token punctuation">]</span><span class="token punctuation">;</span>

real <span class="token function">reduce</span><span class="token punctuation">(</span><span class="token keyword">const</span> real<span class="token operator">*</span> d_x<span class="token punctuation">)</span>
<span class="token punctuation">{</span>
    real<span class="token operator">*</span> d_y<span class="token punctuation">;</span>
    <span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token function">cudaGetSymbolAddress</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_y<span class="token punctuation">,</span> static_y<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">//将指向d_y的指针指向static_y</span>

    <span class="token keyword">const</span> <span class="token keyword">int</span> smem <span class="token operator">=</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>real<span class="token punctuation">)</span> <span class="token operator">*</span> BLOCK_SIZE<span class="token punctuation">;</span>

    reduce_cp<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>GRID_SIZE<span class="token punctuation">,</span> BLOCK_SIZE<span class="token punctuation">,</span> smem<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_x<span class="token punctuation">,</span> d_y<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
    reduce_cp<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>real<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">1024</span><span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_y<span class="token punctuation">,</span> d_y<span class="token punctuation">,</span> GRID_SIZE<span class="token punctuation">)</span><span class="token punctuation">;</span>
  
    real h_y<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token number">0</span><span class="token punctuation">}</span><span class="token punctuation">;</span>
    <span class="token function">CHECK</span><span class="token punctuation">(</span><span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>h_y<span class="token punctuation">,</span> d_y<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span>real<span class="token punctuation">)</span><span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
  
    <span class="token keyword">return</span> h_y<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<code>cudaGetSymbolAddress(void** devPtr, const char* symbol);</code></li>
<li><code>void*8 devPtr</code>：是一个指向指针的指针，函数会修改这个指针，使其指向<strong>指定符号</strong>在设备上的地址</li>
<li><code>const char* symbol</code>：是一个字符串，表示你想要获取地址的符号名称(通常是全局变量或常量变量的名称，需要以<code>__device__</code>或<code>__constant__</code>存储类定义)</li>
<li>使用场景：在设备中定义了一个全局变量或常量，并希望在内核或其他CUDA函数中使用</li>
<li>示例👇<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token comment">// 定义</span>
__device__ <span class="token keyword">float</span> static_y<span class="token punctuation">;</span>
<span class="token comment">// 获取static_y的地址</span>
<span class="token keyword">float</span> <span class="token operator">*</span>d_y<span class="token punctuation">;</span>
<span class="token function">cudaGetSymbolAddress</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span><span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>d_y<span class="token punctuation">,</span> <span class="token string">"static_y"</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
</li>
</ul>
<p>单精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240926190202.png" alt="375"><br>双精度👇<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240926190218.png" alt="375"><br>用时比使用动态全局内存更短！</p>
<h1 id="第十一章-CUDA流"><a href="#第十一章-CUDA流" class="headerlink" title="第十一章 CUDA流"></a>第十一章 CUDA流</h1><p>核函数外部的并行主要指：</p>
<ul>
<li>核函数计算与数据传输之间的并行</li>
<li>主机计算与数据传输之间的并行</li>
<li>不同的数据传输之间的并行(cudaMemcpy函数中的第四个参数)</li>
<li>核函数计算与主机计算之间的并行</li>
<li>不同核函数之间的并行</li>
</ul>
<p>一般来说，要获得较高的加速比，如要<strong>减少主机与设备之间的数据传输及主机中的计算</strong>，<strong>尽量在设备中完成所有计算</strong></p>
<h2 id="11-1-CUDA流概述"><a href="#11-1-CUDA流概述" class="headerlink" title="11.1 CUDA流概述"></a>11.1 CUDA流概述</h2><p><strong>一个CUDA流指的是由主机发出的在一个设备中执行的CUDA操作</strong>(即和CUDA有关的操作，如主机-设备数据传输和核函数执行)<strong>序列</strong></p>
<p>CUDA流：</p>
<ul>
<li>默认流(空流)</li>
<li>非默认流(非空流)<ul>
<li>在主机端产生和销毁</li>
<li>一个CUDA流由类型为<code>cudaStream_t</code>的变量表示</li>
<li>产生：<code>cudaStreamCreate(cudaStream_t*)</code>，输入参数是<code>cudaStream_t</code>类型的指针</li>
<li>销毁：<code>cudaStreamDestroy(cudaStream_t*)</code>，输入参数<code>cudaStream_t</code>类型的变量</li>
<li>检查一个CUDA流中的所有操作是否都在设备中执行完毕：<ul>
<li><code>cudaStreamSynchronize(cudaStream_t stream)</code>，<code>cudaStreamSynchronize()</code>会强制阻塞主机，直到CUDA流stream中的所有操作都被执行完毕</li>
<li><code>cudaStreamQuery(cudaStream_t stream)</code>，<code>cudaStreamQuery()</code>不会阻塞主机，只是检查CUDA流stream中的所有操作是否都执行完毕</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="11-2-在默认流中重叠主机和设备计算"><a href="#11-2-在默认流中重叠主机和设备计算" class="headerlink" title="11.2 在默认流中重叠主机和设备计算"></a>11.2 在默认流中重叠主机和设备计算</h2><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_x<span class="token punctuation">,</span> h_x<span class="token punctuation">,</span> M<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 主机发出命令后，需等待命令执行完毕才执行下一步，在等待的过程中主机闲置</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>d_y<span class="token punctuation">,</span> h_y<span class="token punctuation">,</span> M<span class="token punctuation">,</span> cudaMemcpyHostToDevice<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 主机发出命令后，需等待命令执行完毕才执行下一步，在等待的过程中主机闲置</span>
sum<span class="token operator">&lt;&lt;</span><span class="token operator">&lt;</span>grid_size<span class="token punctuation">,</span> block_size<span class="token operator">&gt;&gt;</span><span class="token operator">&gt;</span><span class="token punctuation">(</span>d_x<span class="token punctuation">,</span> d_y<span class="token punctuation">,</span> d_z<span class="token punctuation">,</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 主机发出命令后，不会等待该命令执行完毕，主机紧接着会发出下一条指令</span>
<span class="token function">cudaMemcpy</span><span class="token punctuation">(</span>h_z<span class="token punctuation">,</span> d_z<span class="token punctuation">,</span> M<span class="token punctuation">,</span> cudaMemcpyDeviceToHost<span class="token punctuation">)</span><span class="token punctuation">;</span> <span class="token comment">// 因为这是默认流中的CUDA操作，必须等待前一个CUDA操作执行完毕才会执行这条命令</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<p>👆CUDA操作例子(注释是主机角度)<br>从设备角度看：上面4个CUDA操作在默认的CUDA流中<strong>按代码出现的顺序依次执行</strong><br>从主机角度看：<br>①主机在发出核函数命令的调用后会立刻发出下一个命令<br>②(1)如果下一个命令是数据传输，从设备角度看必须等待核函数执行完毕(实际上主机也在等执行完毕)<br>②(2)如果下一个命令是主机中的某个计算任务，那么主机会在设备执行核函数时同时进行一些计算，这样主机和设备就可以同时进行(<strong>设备完全不知道在它执行核函数时，主机偷偷地做了些计算</strong>)</p>
<p>实践(结果和书上的不符合)：</p>
<ul>
<li>采用单精度浮点数，在数据量一样时，<strong>核函数<code>gpu_sum</code>比主机端函数<code>cpu_sum</code>约快10倍</strong>，因此设置$ratio=\dfrac{设备端函数所处理的数据量}{主机端函数所处理的数据量}$，使得<code>gpu_sum</code>和<code>cpu_sum</code>执行时间差不多</li>
<li>这里的结果和书上的不太符合(思考.jpg)</li>
</ul>
<p>结果(书上的)：</p>
<ul>
<li>当主机函数和设备函数的计算量相当时，将<strong>主机函数放在设备函数之后</strong>(GPU -&gt; CPU)可以达到主机函数与设备函数并发执行的效果，从而有效地隐藏主机函数的执行过程</li>
<li>如果主机函数和设备函数计算时间差很多，加速效果不显著</li>
</ul>
<h2 id="11-3-用非默认CUDA流重叠多个核函数的执行"><a href="#11-3-用非默认CUDA流重叠多个核函数的执行" class="headerlink" title="11.3 用非默认CUDA流重叠多个核函数的执行"></a>11.3 用非默认CUDA流重叠多个核函数的执行</h2><p>同一个CUDA流中的<strong>CUDA操作在设备中是顺序执行的</strong>(非并行)，那么同一个CUDA流中的<strong>核函数</strong>也必须在设备中<strong>顺序执行</strong>，如果要实现<strong>多个核函数之间的并行</strong>必须使用<strong>多个CUDA流</strong></p>
<p>核函数的调度方式<br><code>my_kernel&lt;&lt;&lt;N_grid, N_block&gt;&gt;&gt;();</code> -&gt; 在默认流执行<br><code>my_kernel&lt;&lt;&lt;N_grid, N_block, N_shared&gt;&gt;&gt;();</code> -&gt; 在默认流执行<br><code>my_kernel&lt;&lt;&lt;N_grid, N_block, N_shared, stream_id&gt;&gt;&gt;();</code> -&gt; 非空流执行</p>
<ul>
<li><code>N_grid</code>是网格大小</li>
<li><code>N_block</code>是线程块大小</li>
<li><code>N_shared</code>是核函数中使用的<strong>动态共享内存</strong>的<strong>字节数</strong></li>
<li><code>stream_id</code>是CUDA流的编号</li>
</ul>
<p>可能是设备不同的问题，和书上的结果不太一样<br><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/Pasted%20image%2020240928191804.png" alt="500"><br>结果(书上的)：<br>CUDA流并发多个核函数可以提升GPU硬件的利用率，减少闲置的SM，从而从整体上获得性能提升</p>
<h2 id="11-4-用非默认CUDA流重叠核函数的执行与数据传递"><a href="#11-4-用非默认CUDA流重叠核函数的执行与数据传递" class="headerlink" title="11.4 用非默认CUDA流重叠核函数的执行与数据传递"></a>11.4 用非默认CUDA流重叠核函数的执行与数据传递</h2><p>若需要实现核函数执行与数据传输的并发(重叠)</p>
<ul>
<li>必须让这两个操作处于不同的非默认流</li>
<li>数据传输需要使用异步版本<code>cudaMemcpyAsync()</code>函数<ul>
<li>异步传输由GPU中的DMA(direct memory access)直接存储访问器，不需要主机参与<ul>
<li>DMA提供在<strong>外设和存储器之间</strong>或者<strong>存储器和存储器之间</strong>的高速数据传输</li>
<li>数据的复制和存储数据对于CPU来说没那么重要，可以交给DMA，解决大量数据转移过度消耗CPU资源的问题</li>
</ul>
</li>
<li>如果用同步的数据传输函数<code>cudaMemcpy()</code>，主机向一个流发出数据传输的命令后<strong>无法立刻获得控制权</strong>，必须等待数据传输完毕，即主机无法同时向另一个流调用核函数，也就不能实现核函数与数据传输的重叠</li>
<li><code>cudaMemcpyAsync(void *dst, const void *src, size_t count, enum cudaMemcpyKind kind, cudaStream_t stream)</code>比<code>cudaMemcpy()</code>多一个参数，是所<strong>在流的变量</strong></li>
<li>在使用异步的数据传输时，需要将主机内存定义为不可分页内存或者固定内存<ul>
<li>不可分页内存：若将主机内存声明为不可分页内存，则在程序运行期间其物理地址<strong>保持不变</strong></li>
<li>系统操作有权在一个程序运行期间改变程序中使用的<strong>可分页主机内存</strong>的物理地址</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>不可分页<strong>主机内存</strong>的分配函数</p>
<ul>
<li><code>cudaMallocHost(void **ptr, size_t size);</code></li>
<li><code>cudaHostAlloc(void **ptr, size_t size, size_t flags);</code>，如果第三个参数取默认值<code>cudaHostAlllocDefault</code>，则和上面的函数等价<br>不可分页<strong>主机内存</strong>的释放函数</li>
<li><code>cudaFreeHost(void *ptr);</code></li>
</ul>
<p>这里的时间是把前几次REPEAT次数的时间也加上了</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>CUDA流=1</th>
<th>2</th>
<th>4</th>
<th>8</th>
<th>16</th>
<th>32</th>
<th>64</th>
</tr>
</thead>
<tbody>
<tr>
<td>REPEAT次数=1</td>
<td>0.727245</td>
<td>0.813056</td>
<td>0.671984</td>
<td>0.633242</td>
<td>0.640717</td>
<td>0.732979</td>
<td>0.711456</td>
</tr>
<tr>
<td>2</td>
<td>1.48132</td>
<td>1.6044</td>
<td>1.29539</td>
<td>1.25809</td>
<td>1.2987</td>
<td>1.37727</td>
<td>1.40511</td>
</tr>
<tr>
<td>3</td>
<td>2.15654</td>
<td>2.40559</td>
<td>1.94911</td>
<td>1.89739</td>
<td>1.98509</td>
<td>2.0228</td>
<td>2.10539</td>
</tr>
<tr>
<td>4</td>
<td>2.90161</td>
<td>3.17943</td>
<td>2.62284</td>
<td>2.54855</td>
<td>2.64568</td>
<td>2.66245</td>
<td>2.8182</td>
</tr>
<tr>
<td>5</td>
<td>3.5848</td>
<td>3.97385</td>
<td>3.29006</td>
<td>3.16776</td>
<td>3.29783</td>
<td>3.32314</td>
<td>3.53272</td>
</tr>
<tr>
<td>6</td>
<td>4.2719</td>
<td>4.79479</td>
<td>3.97973</td>
<td>3.8308</td>
<td>3.96661</td>
<td>4.00003</td>
<td>4.19064</td>
</tr>
<tr>
<td>7</td>
<td>5.04011</td>
<td>5.60569</td>
<td>4.61964</td>
<td>4.49671</td>
<td>4.65433</td>
<td>4.62836</td>
<td>4.84917</td>
</tr>
<tr>
<td>8</td>
<td>5.90314</td>
<td>6.3983</td>
<td>5.27192</td>
<td>5.15115</td>
<td>5.28048</td>
<td>5.26508</td>
<td>5.52204</td>
</tr>
<tr>
<td>9</td>
<td>6.73892</td>
<td>7.15903</td>
<td>5.94195</td>
<td>5.7894</td>
<td>5.90922</td>
<td>5.90743</td>
<td>6.19399</td>
</tr>
<tr>
<td>10</td>
<td>7.55339</td>
<td>8.02287</td>
<td>6.58859</td>
<td>6.41499</td>
<td>6.53621</td>
<td>6.56247</td>
<td>6.8724</td>
</tr>
</tbody>
</table>
</div>
<p>看起来并行效果是还不错的。</p>
<h1 id="第十四章-CUDA标准库的使用"><a href="#第十四章-CUDA标准库的使用" class="headerlink" title="第十四章 CUDA标准库的使用"></a>第十四章 CUDA标准库的使用</h1><h2 id="14-2-Thrust库"><a href="#14-2-Thrust库" class="headerlink" title="14.2 Thrust库"></a>14.2 Thrust库</h2><ul>
<li>Thrust库是一个实现了<strong>众多基本并行算法</strong>的C++模板库</li>
<li>该库中的所有类型与函数都在命名空间thrust中定义，所以用到<code>thrust::</code>开头</li>
<li>Thrust中有两种矢量：<ul>
<li><code>thrust::host_vector&lt;typename&gt;</code>，存储于主机中</li>
<li><code>thrust::device_vector&lt;typename&gt;</code>，存储于设备中<ul>
<li><code>thrust::devive_vectot&lt;double&gt; x(10, 0);</code>，元素类型为双精度浮点数(全部初始化为0)，长度为10</li>
</ul>
</li>
</ul>
</li>
<li>除了<code>thrust::copy</code>，Thrust算法的参数必须<strong>都</strong>来自于主机矢量或<strong>都</strong>来自于设备矢量，否则编译器会报错</li>
</ul>
<h3 id="14-2-4-例子：前缀和"><a href="#14-2-4-例子：前缀和" class="headerlink" title="14.2.4 例子：前缀和"></a>14.2.4 例子：前缀和</h3><ol>
<li>使用<code>device_vector</code>来实现<pre class="line-numbers language-c" data-language="c"><code class="language-c">thrust<span class="token operator">::</span><span class="token function">device_vector</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span> <span class="token function">x</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
thrust<span class="token operator">::</span><span class="token function">device_vector</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span> <span class="token function">y</span><span class="token punctuation">(</span>N<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
</ol>
<ul>
<li>扫描操作<pre class="line-numbers language-c" data-language="c"><code class="language-c">thrust<span class="token operator">::</span><span class="token function">inclusive_scan</span><span class="token punctuation">(</span>x<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> x<span class="token punctuation">.</span><span class="token function">end</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> y<span class="token punctuation">.</span><span class="token function">begin</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<code>thrust::inclusive_scan(InputIterator begin, InputIterator end, OutputIterator result);</code><br>  <code>InputIterator begin</code> 输入范围的起始迭代器。<br>  <code>InputIterator end</code>: 输入范围的结束迭代器。<br>  <code>OutputIterator result</code>: 用于存储结果的输出范围起始迭代器。<br>  这里的迭代器可以理解为指针的推广<br>例子中使用了<code>thrust::inclusive_scan(x.begin(), x.end(), y.begin());</code></li>
<li>输出<br><code>y</code>是设备矢量，<code>y[i]</code>不是普通整型的变量，需要强制转化为整型后才能用<code>printf()</code>函数输出。用C++的输入/输出流可以直接输出<code>y[i]</code>而不需要先做强制类型转换</li>
</ul>
<ol>
<li>直接用设备中的数组(指针)实现</li>
</ol>
<ul>
<li>定义<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>x<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span> <span class="token operator">*</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">cudaMalloc</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token keyword">void</span> <span class="token operator">*</span><span class="token operator">*</span><span class="token punctuation">)</span><span class="token operator">&amp;</span>y<span class="token punctuation">,</span> <span class="token keyword">sizeof</span><span class="token punctuation">(</span><span class="token keyword">int</span><span class="token punctuation">)</span> <span class="token operator">*</span> N<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre></li>
<li><p>扫描操作</p>
<pre class="line-numbers language-c" data-language="c"><code class="language-c">thrust<span class="token operator">::</span><span class="token function">inclusive_scan</span><span class="token punctuation">(</span>thrust<span class="token operator">::</span>device<span class="token punctuation">,</span> x<span class="token punctuation">,</span> x <span class="token operator">+</span> N<span class="token punctuation">,</span> y<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<p>对于使用设备矢量的版本，该函数用了一个额外的<strong>表示执行策略的参数</strong><code>thrust::device</code>，需要包含头文件<code>&lt;thrust/execution_policy.h&gt;</code></p>
</li>
<li><p>如果大量使用Thrust库提供的功能，使用设备矢量</p>
</li>
<li>如果偶尔使用Thrust库提供的功能，使用设备指针</li>
</ul>
<h2 id="14-3-cuBLAS库"><a href="#14-3-cuBLAS库" class="headerlink" title="14.3 cuBLAS库"></a>14.3 cuBLAS库</h2><p>行主序和列主序，前者要求矩阵的每一行元素在内存中是连续的，后者以此类推</p>
<p>cuBLAS库包含3个API，其中一个为<code>cuBLAS API</code>，可以实现BLAS三个层级的函数</p>
<ul>
<li>第一层函数处理矢量之间的运算</li>
<li>第二层函数处理矩阵和矢量之间的运算</li>
<li>第三层函数处理矩阵之间的运算</li>
</ul>
<h3 id="14-3-2-例子：矩阵乘法"><a href="#14-3-2-例子：矩阵乘法" class="headerlink" title="14.3.2 例子：矩阵乘法"></a>14.3.2 例子：矩阵乘法</h3><p><img src="https://raw.githubusercontent.com/Wabbybabb0/Blog_picture/refs/heads/main/CUDAC/249b3070465d0ba1c51fff0da2c2ac6.jpg" alt="|400"><br>使用<code>cuBLAS</code>时使用<code>&lt;cublas_v2.h&gt;</code>作为头文件<br>在初始化<code>h_A</code>、<code>h_B</code>、<code>h_C</code>时用一维矢量来表示矩阵</p>
<ol>
<li>主机数组和设备数组的复制</li>
</ol>
<ul>
<li>从主机数组复制到设备数组<pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token class-name">cublasStatus_t</span> <span class="token function">cublasSetVector</span>
<span class="token punctuation">(</span>
	<span class="token keyword">int</span> n<span class="token punctuation">,</span>
	<span class="token keyword">int</span> elemSize<span class="token punctuation">,</span>
	cosnt <span class="token keyword">void</span> <span class="token operator">*</span>x<span class="token punctuation">,</span>
	<span class="token keyword">int</span> incx<span class="token punctuation">,</span>
	<span class="token keyword">void</span> <span class="token operator">*</span>y<span class="token punctuation">,</span>
	<span class="token keyword">int</span> incy
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<code>n</code>：复制的元素个数<br><code>elemSize</code>：每个元素的字节数<br><code>incx</code>/<code>incy</code>：表示对数组x/y进行访问时每incx/incy个数据中取一个<br><code>x</code>：主机数组<br><code>y</code>：设备数组<br>例：<code>cublasSetVector(MK, sizeof(double), h_A, 1, g_A, 1);</code></li>
<li>从设备数组复制到主机数组<br><code>cublasGetVector()</code>其中参数相同，顺序不同<br>例：<code>cublasGetVector(MK, sizeof(double), g_A, 1, h_A, 1);</code></li>
</ul>
<ol>
<li>矩阵乘法计算</li>
</ol>
<ul>
<li>定义一个<code>cublasHandle</code>类型的变量并用<code>cublasCreate()</code>函数初始化</li>
<li>调用<code>cublasDgemm()</code>函数做矩阵相乘的计算<ul>
<li>是第三层的<code>cuBLAS</code>函数之一</li>
<li><code>D</code>：double</li>
<li><code>gemm</code>：GEneral Matrix-Matrix multiplication</li>
<li>执行如下计算<code>C = alpha * transa(A) * transb(B) + beta * C</code><ul>
<li><code>transa(A)</code>是对矩阵<code>A</code>做一个变换之后得到的矩阵，维度是<code>m × k</code></li>
<li><code>transb(B)</code>是对矩阵<code>B</code>做一个变换之后得到的矩阵，维度是<code>k × n</code></li>
<li><code>C</code>的维度是<code>m × n</code><pre class="line-numbers language-c" data-language="c"><code class="language-c"><span class="token function">cublasDgemm</span>
<span class="token punctuation">(</span>
	<span class="token class-name">cublasHandle_t</span> handle<span class="token punctuation">,</span>
	<span class="token class-name">cublasOperation_t</span> transa<span class="token punctuation">,</span>
	<span class="token class-name">cublasOperation_t</span> transb<span class="token punctuation">,</span>
	<span class="token keyword">int</span> m<span class="token punctuation">,</span>
	<span class="token keyword">int</span> n<span class="token punctuation">,</span>
	<span class="token keyword">int</span> k<span class="token punctuation">,</span>
	<span class="token keyword">const</span> <span class="token keyword">double</span> <span class="token operator">*</span>alpha<span class="token punctuation">,</span>
	<span class="token keyword">const</span> <span class="token keyword">double</span> <span class="token operator">*</span>A<span class="token punctuation">,</span>
	<span class="token keyword">int</span> lda<span class="token punctuation">,</span>
	<span class="token keyword">const</span> <span class="token keyword">double</span> <span class="token operator">*</span>B<span class="token punctuation">,</span>
	<span class="token keyword">int</span> ldb<span class="token punctuation">,</span>
	<span class="token keyword">const</span> <span class="token keyword">double</span> <span class="token operator">*</span>beta<span class="token punctuation">,</span>
	<span class="token keyword">double</span> <span class="token operator">*</span>C<span class="token punctuation">,</span>
	<span class="token keyword">int</span> ldc
<span class="token punctuation">)</span><span class="token punctuation">;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<code>cublasOperation_t transa</code>中<code>transa</code>为：</li>
</ul>
</li>
</ul>
</li>
<li><code>cuBLAS_OP_N</code>，<code>transa(A)</code>等于<code>A</code></li>
<li><code>cuBLAS_OP_T</code>，<code>transa(A)</code>等于<code>A</code>的转置</li>
<li><code>cuBLAS_OP_C</code>，<code>transa(A)</code>等于<code>A</code>的共轭转置<br><code>lda</code>、<code>ldb</code>和<code>ldc</code>分别是<code>transa(A)</code>、<code>transa(B)</code>和<code>C</code>的主维度，他们都是列主序，所以他们的主维度是矩阵的行数</li>
</ul>
<p>最后的结果<code>h_C</code>是列主序的(10 13 28 40)，打印时需要注意</p>
<h1 id="补充Event"><a href="#补充Event" class="headerlink" title="补充Event"></a>补充Event</h1><ul>
<li><strong>创建事件</strong>：首先使用 <code>cudaEventCreate()</code> 创建事件对象。</li>
<li><strong>记录事件</strong>：在需要记录的时间点调用 <code>cudaEventRecord(event, stream)</code>。</li>
<li><strong>计算时间</strong>：通过 <code>cudaEventElapsedTime()</code> 计算两个事件之间的时间差。</li>
<li><strong>销毁事件</strong>：最后使用 <code>cudaEventDestroy()</code> 销毁事件对象以释放资源。</li>
<li><strong>同步</strong>：<code>cudaEventSynchronize(stop)</code> 会阻塞 CPU，直到 GPU 确保从 <code>start</code> 到 <code>stop</code> 之间的所有操作都完成了。这对于测量内核函数执行时间或在 CPU 侧进行同步非常重要。</li>
<li><strong>检查事件是否完成</strong>：<code>cudaEventQuery(start)</code>它的主要功能是<strong>检查指定的 CUDA 事件是否已经完成</strong>，而不需要阻塞主机线程。<code>cudaEventQuery</code> 常用于需要频繁检查事件状态的场景。和 <code>cudaEventSynchronize</code> 不同，<code>cudaEventQuery</code> 是非阻塞的，不会让 CPU 等待 GPU 任务完成，而只是检查 GPU 的执行状态。如果事件还未完成，它会立即返回 <code>cudaErrorNotReady</code>，让程序可以继续执行其他任务。</li>
</ul>
<h1 id="补充运行"><a href="#补充运行" class="headerlink" title="补充运行"></a>补充运行</h1><p><code>$nvcc -arch=_75 add1.cu -o add1</code>，选择真实架构计算能力<br><code>$nvcc -O3 -arch=_75 add1.cu -o add1</code>，选择最激进的优化，生成最快的代码，但可能会增加编译时间和二进制文件大小。(C++程序的性能显著地依赖于优化选项)<br><code>$nvcc -O3 -arch=sm_75 -DUSE_DP add1.cu -o add1</code>使用<code>if</code>的选项，不写<code>-DUSE_DP</code>的话使用<code>else</code>的选项</p>
<h1 id="补充C-语法"><a href="#补充C-语法" class="headerlink" title="补充C++语法"></a>补充C++语法</h1><p><code>void read_xy(std::vector&lt;real&gt;&amp; x, std::vector&lt;real&gt; y);</code>：</p>
<ul>
<li><code>std::vector</code>：C++的动态数组，大小是动态的</li>
<li><code>std::vector&lt;real&gt;&amp; x</code>：对于<code>x</code>是引用传递，在<code>read_xy</code>函数内部对<code>x</code>的任何修改，都会直接影响到他们本身(而不是副本)，对外部的<code>x</code>也会有影响</li>
</ul>
<p><code>std::ifstream infile("xy.txt");</code></p>
<ul>
<li><code>std::ifstream</code>：表示输入文件流，用于从文件读取数据</li>
<li><code>infile</code>：用来打开文件并读取内容</li>
</ul>
<p><code>std::ofstream outfile("neighbor.txt");</code></p>
<ul>
<li><code>std::ofstream</code>：表示输出文件流，将数据写入到文件中</li>
</ul>
<p><code>std::istringstream words(line);</code></p>
<ul>
<li><code>std::istringstream</code>：表示输入字符串流，可以从一个字符串中逐个提取数据</li>
<li><code>words</code>：从字符串中提取数据</li>
<li>这段代码作用：使用<code>words</code>来逐个读取<code>line</code>中的单词或数据</li>
</ul>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">WB</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://wabbybabb0.github.io/2024/08/02/cudac/">https://wabbybabb0.github.io/2024/08/02/cudac/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">WB</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/CUDA/">
                                    <span class="chip bg-color">CUDA</span>
                                </a>
                            
                                <a href="/tags/GPU/">
                                    <span class="chip bg-color">GPU</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">给WB来包辣条</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    
        <div class="card" data-aos="fade-up">
    <div id="utteranc-container" class="card-content">
        <script src="https://utteranc.es/client.js"
                repo="Wabbybabb0/commit-utterance"
                issue-term="pathname"
                theme="github-light"
                crossorigin="anonymous"
                async>
        </script>
    </div>
</div>
    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2024/10/08/llm2-tui-li-yin-qing/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/11.png" class="responsive-img" alt="LLM2框架搭建过程">
                        
                        <span class="card-title">LLM2框架搭建过程</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            参照"不归牛顿管的熊猫"的课程视频搭建的LLM2框架，目前还在对算子进行调试优化阶段
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2024-10-08
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97/" class="post-category">
                                    高性能计算
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/LLM/">
                        <span class="chip bg-color">LLM</span>
                    </a>
                    
                    <a href="/tags/CUDA/">
                        <span class="chip bg-color">CUDA</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2024/01/27/mlc-llm-orangepi-bu-shu-guo-cheng/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/9.png" class="responsive-img" alt="mlc-llm 香橙派部署过程">
                        
                        <span class="card-title">mlc-llm 香橙派部署过程</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            mlc-llm部署
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2024-01-27
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/" class="post-category">
                                    人工智能
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/">
                        <span class="chip bg-color">人工智能</span>
                    </a>
                    
                    <a href="/tags/NLP/">
                        <span class="chip bg-color">NLP</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>


<script>
    $('#articleContent').on('copy', function (e) {
        // IE8 or earlier browser is 'undefined'
        if (typeof window.getSelection === 'undefined') return;

        var selection = window.getSelection();
        // if the selection is short let's not annoy our users.
        if (('' + selection).length < Number.parseInt('120')) {
            return;
        }

        // create a div outside of the visible area and fill it with the selected text.
        var bodyElement = document.getElementsByTagName('body')[0];
        var newdiv = document.createElement('div');
        newdiv.style.position = 'absolute';
        newdiv.style.left = '-99999px';
        bodyElement.appendChild(newdiv);
        newdiv.appendChild(selection.getRangeAt(0).cloneContents());

        // we need a <pre> tag workaround.
        // otherwise the text inside "pre" loses all the line breaks!
        if (selection.getRangeAt(0).commonAncestorContainer.nodeName === 'PRE') {
            newdiv.innerHTML = "<pre>" + newdiv.innerHTML + "</pre>";
        }

        var url = document.location.href;
        newdiv.innerHTML += '<br />'
            + '来源: Wabbybabbo的摸鱼圣地<br />'
            + '文章作者: Wabbybabbo<br />'
            + '文章链接: <a href="' + url + '">' + url + '</a><br />'
            + '本文章著作权归作者所有，任何形式的转载都请注明出处。';

        selection.selectAllChildren(newdiv);
        window.setTimeout(function () {bodyElement.removeChild(newdiv);}, 200);
    });
</script>


<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"] ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    




<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.8/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\(', '\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="8590828427"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2023-2025</span>
            
            <span id="year">2023</span>
            <a href="/about" target="_blank">Wabbybabbo</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/Wabbybabb0" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:Wabbybabb0@outlook.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=497056512" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 497056512" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
